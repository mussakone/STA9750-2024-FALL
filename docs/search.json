[
  {
    "objectID": "mp03.html#task-1-download-congressional-shapefiles-1976-2012",
    "href": "mp03.html#task-1-download-congressional-shapefiles-1976-2012",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "Task 1: Download Congressional Shapefiles 1976-2012",
    "text": "Task 1: Download Congressional Shapefiles 1976-2012\nIn this task, we aim to automate the process of downloading U.S. congressional district shapefiles for each Congress from 1976 to 2012. These shapefiles, provided by Lewis et al., allow us to visualize and analyze geographic boundaries that define congressional districts over time.\n\n\nClick to Show/Hide Code\n# Load required libraries\nlibrary(httr)    # For HTTP requests\nlibrary(glue)    # For formatted strings\nlibrary(fs)      # For file and directory handling\n\n# Set up directory for shapefiles\ndownload_dir &lt;- \"data/shapefiles\"\nif (!dir_exists(download_dir)) dir_create(download_dir)\n\n# Define base URL and range of Congress sessions\nbase_url &lt;- \"https://cdmaps.polisci.ucla.edu/shp/districts\"\ncongress_years &lt;- seq(94, 112)  # Congresses from 1976 to 2012 (94th to 112th)\n\n# Loop through Congress sessions to download shapefiles\nfor (congress in congress_years) {\n  # Define file name and path\n  zip_file_name &lt;- glue(\"c{congress}_dist.zip\")\n  zip_file_path &lt;- path(download_dir, zip_file_name)\n  \n  # Download only if the file does not already exist\n  if (!file_exists(zip_file_path)) {\n    # Construct the download URL\n    download_url &lt;- glue(\"{base_url}/{zip_file_name}\")\n    \n    # Try downloading the file\n    cat(\"Attempting to download:\", download_url, \"\\n\")\n    response &lt;- tryCatch({\n      GET(download_url, write_disk(zip_file_path, overwrite = TRUE))\n    }, error = function(e) {\n      cat(\"Error downloading:\", zip_file_name, \"\\n\")\n      NULL\n    })\n    \n    # Check if the download was successful\n    if (!is.null(response) && status_code(response) == 200) {\n      cat(\"Downloaded:\", zip_file_name, \"\\n\")\n      \n      # Extract .shp files from the zip file if download successful\n      extracted_dir &lt;- path(download_dir, glue(\"congress_{congress}\"))\n      if (!dir_exists(extracted_dir)) dir_create(extracted_dir)\n      \n      # Unzip only the .shp files\n      shp_files &lt;- grep(\"\\\\.shp$\", unzip(zip_file_path, list = TRUE)$Name, value = TRUE)\n      unzip(zip_file_path, files = shp_files, exdir = extracted_dir)\n      cat(\"Extracted shapefiles for Congress\", congress, \"\\n\")\n    }\n  } else {\n    cat(\"File already exists:\", zip_file_name, \"- Skipping download.\\n\")\n  }\n}\n\n\nFile already exists: c94_dist.zip - Skipping download.\nFile already exists: c95_dist.zip - Skipping download.\nFile already exists: c96_dist.zip - Skipping download.\nFile already exists: c97_dist.zip - Skipping download.\nFile already exists: c98_dist.zip - Skipping download.\nFile already exists: c99_dist.zip - Skipping download.\nFile already exists: c100_dist.zip - Skipping download.\nFile already exists: c101_dist.zip - Skipping download.\nFile already exists: c102_dist.zip - Skipping download.\nFile already exists: c103_dist.zip - Skipping download.\nFile already exists: c104_dist.zip - Skipping download.\nFile already exists: c105_dist.zip - Skipping download.\nFile already exists: c106_dist.zip - Skipping download.\nFile already exists: c107_dist.zip - Skipping download.\nFile already exists: c108_dist.zip - Skipping download.\nFile already exists: c109_dist.zip - Skipping download.\nFile already exists: c110_dist.zip - Skipping download.\nFile already exists: c111_dist.zip - Skipping download.\nFile already exists: c112_dist.zip - Skipping download.\n\n\nClick to Show/Hide Code\ncat(\"All shapefiles processed successfully.\\n\")\n\n\nAll shapefiles processed successfully."
  },
  {
    "objectID": "mp03.html#task-2-automated-download-of-congressional-shapefiles-2014-2022",
    "href": "mp03.html#task-2-automated-download-of-congressional-shapefiles-2014-2022",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "Task 2: Automated Download of Congressional Shapefiles (2014-2022)",
    "text": "Task 2: Automated Download of Congressional Shapefiles (2014-2022)\nIn this task, we aim to automate the process of downloading congressional district shapefiles for each U.S. Congress from 2014 to 2022. These shapefiles, available from the U.S. Census Bureau, provide geographical boundary data for congressional districts, which is crucial for spatial analysis and mapping of political and demographic trends. Additionally, we will extract only the necessary .shp files from each downloaded zip archive, organizing them with a clear naming convention for easy reference in future analysis. This structured approach will facilitate accurate and reproducible results for any subsequent spatial analyses or visualizations involving U.S. congressional districts.\n\n\nClick to Show/Hide Code\n# Load required libraries\nlibrary(httr)    # For HTTP requests\nlibrary(glue)    # For formatted strings\nlibrary(fs)      # For file and directory handling\nlibrary(xml2)    # For parsing HTML content\nlibrary(rvest)   # For web scraping\n\n\n\nAttaching package: 'rvest'\n\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n\nClick to Show/Hide Code\n# Define base URL and create download directory\nbase_url &lt;- \"https://www2.census.gov/geo/tiger/TIGER{year}/CD/\"\ndownload_dir &lt;- \"data/congress_shapefiles\"\nif (!dir_exists(download_dir)) dir_create(download_dir)\n\n# Define the years corresponding to each Congress session (2014-2022)\nyears &lt;- seq(2014, 2022, 2)\n\n# Function to download and extract shapefiles for each year\nfor (year in years) {\n  year_url &lt;- glue(base_url, year = year)\n  \n  # Get list of zip files available for each year\n  page &lt;- tryCatch({\n    read_html(year_url)\n  }, error = function(e) {\n    cat(\"Could not access:\", year_url, \"\\n\")\n    return(NULL)\n  })\n  \n  # If the page was successfully accessed, proceed\n  if (!is.null(page)) {\n    # Get links to all zip files in the directory\n    zip_files &lt;- page %&gt;% html_nodes(\"a\") %&gt;% html_attr(\"href\") %&gt;% \n                 .[grepl(\"\\\\.zip$\", .)]\n    \n    # Download each zip file\n    for (zip_file in zip_files) {\n      file_name &lt;- glue(\"congress_{year}_{zip_file}\")\n      file_path &lt;- path(download_dir, file_name)\n      file_url &lt;- paste0(year_url, zip_file)\n      \n      # Download only if the file does not already exist\n      if (!file_exists(file_path)) {\n        cat(\"Downloading:\", file_url, \"\\n\")\n        GET(file_url, write_disk(file_path, overwrite = TRUE))\n        \n        # Extract the .shp file from the zip\n        extracted_dir &lt;- path(download_dir, glue(\"congress_{year}\"))\n        if (!dir_exists(extracted_dir)) dir_create(extracted_dir)\n        \n        unzip(file_path, exdir = extracted_dir)\n        cat(\"Extracted shapefiles for Congress session:\", year, \"\\n\")\n      } else {\n        cat(\"File already exists:\", file_name, \"- Skipping download.\\n\")\n      }\n    }\n  }\n}\n\n\nFile already exists: congress_2014_tl_2014_us_cd114.zip - Skipping download.\nFile already exists: congress_2016_tl_2016_us_cd115.zip - Skipping download.\nFile already exists: congress_2018_tl_2018_us_cd116.zip - Skipping download.\nFile already exists: congress_2020_tl_2020_us_cd116.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_01_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_02_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_04_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_05_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_06_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_08_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_09_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_10_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_11_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_12_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_13_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_15_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_16_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_17_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_18_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_19_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_20_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_21_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_22_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_23_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_24_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_25_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_26_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_27_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_28_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_29_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_30_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_31_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_32_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_33_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_34_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_35_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_36_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_37_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_38_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_39_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_40_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_41_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_42_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_44_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_45_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_46_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_47_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_48_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_49_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_50_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_51_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_53_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_54_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_55_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_56_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_60_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_66_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_69_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_72_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_78_cd118.zip - Skipping download.\nFile already exists: congress_2022_tl_2022_us_cd116.zip - Skipping download.\n\n\nClick to Show/Hide Code\ncat(\"All congressional shapefiles processed successfully.\\n\")\n\n\nAll congressional shapefiles processed successfully."
  },
  {
    "objectID": "mp03.html#task-3-exploration-of-vote-count-data",
    "href": "mp03.html#task-3-exploration-of-vote-count-data",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "Task 3: Exploration Of Vote Count Data",
    "text": "Task 3: Exploration Of Vote Count Data\nThis task will require to go back to data we intially downloaded at the start of this report to answer several questions regarding the House of Representatives, the fusion system, and presidential candidate trends in different states."
  },
  {
    "objectID": "mp03.html#which-states-have-gained-and-lost-the-most-seats-in-the-us-house-of-representatives-between-1976-and-2022",
    "href": "mp03.html#which-states-have-gained-and-lost-the-most-seats-in-the-us-house-of-representatives-between-1976-and-2022",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "1. Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?",
    "text": "1. Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\n\nClick to Show/Hide Code\n# Load necessary libraries\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nClick to Show/Hide Code\nlibrary(readr)\nlibrary(knitr)\n\n# Load the data\n  house_data &lt;- read_csv(file.path(data_dir, \"1976-2022-house.csv\"))\n\n\nRows: 32452 Columns: 20\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): state, state_po, office, stage, candidate, party, mode\ndbl (8): year, state_fips, state_cen, state_ic, district, candidatevotes, to...\nlgl (5): runoff, special, writein, unofficial, fusion_ticket\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nClick to Show/Hide Code\n# Count unique districts per state and year\ndistrict_counts &lt;- house_data %&gt;%\n  filter(!is.na(district)) %&gt;%\n  group_by(year, state) %&gt;%\n  summarize(num_districts = n_distinct(district), .groups = 'drop')\n\n# Get counts for 1976 and 2022\ndistrict_counts_1976 &lt;- district_counts %&gt;% filter(year == 1976) %&gt;% select(state, num_districts)\ndistrict_counts_2022 &lt;- district_counts %&gt;% filter(year == 2022) %&gt;% select(state, num_districts)\n\n# Calculate change in seats from 1976 to 2022\nseat_changes &lt;- district_counts_2022 %&gt;%\n  rename(num_districts_2022 = num_districts) %&gt;%\n  inner_join(district_counts_1976, by = \"state\", suffix = c(\"_2022\", \"_1976\")) %&gt;%\n  mutate(seat_change = num_districts_2022 - num_districts) %&gt;%\n  arrange(desc(seat_change))\n\n# Top 5 states with most gain and most loss in seats\nseat_changes_top_gain_loss &lt;- seat_changes %&gt;%\n  slice(c(1:5, (n()-4):n()))\n\n# Display the result as a formatted table\nkable(seat_changes_top_gain_loss, caption = \"Top 5 States with Most Gains and Losses in House Seats (1976-2022)\")\n\n\n\nTop 5 States with Most Gains and Losses in House Seats (1976-2022)\n\n\nstate\nnum_districts_2022\nnum_districts\nseat_change\n\n\n\n\nTEXAS\n38\n24\n14\n\n\nFLORIDA\n28\n15\n13\n\n\nCALIFORNIA\n52\n43\n9\n\n\nARIZONA\n9\n4\n5\n\n\nGEORGIA\n14\n10\n4\n\n\nMICHIGAN\n13\n19\n-6\n\n\nILLINOIS\n17\n24\n-7\n\n\nOHIO\n15\n23\n-8\n\n\nPENNSYLVANIA\n17\n25\n-8\n\n\nNEW YORK\n26\n39\n-13"
  },
  {
    "objectID": "mp03.html#new-york-state-has-a-unique-fusion-voting-system-where-one-candidate-can-appear-on-multiple-lines-on-the-ballot-and-their-vote-counts-are-totaled.-for-instance-in-2022-jerrold-nadler-appeared-on-both-the-democrat-and-working-families-party-lines-for-nys-12th-congressional-district.-he-received-200890-votes-total-184872-as-a-democrat-and-16018-as-wfp-easily-defeating-michael-zumbluskas-who-received-44173-votes-across-three-party-lines-republican-conservative-and-parent.are-there-any-elections-in-our-data-where-the-election-would-have-had-a-different-outcome-if-the-fusion-system-was-not-used-and-candidates-only-received-the-votes-their-received-from-their-major-party-line-democrat-or-republican-and-not-their-total-number-of-votes-across-all-lines",
    "href": "mp03.html#new-york-state-has-a-unique-fusion-voting-system-where-one-candidate-can-appear-on-multiple-lines-on-the-ballot-and-their-vote-counts-are-totaled.-for-instance-in-2022-jerrold-nadler-appeared-on-both-the-democrat-and-working-families-party-lines-for-nys-12th-congressional-district.-he-received-200890-votes-total-184872-as-a-democrat-and-16018-as-wfp-easily-defeating-michael-zumbluskas-who-received-44173-votes-across-three-party-lines-republican-conservative-and-parent.are-there-any-elections-in-our-data-where-the-election-would-have-had-a-different-outcome-if-the-fusion-system-was-not-used-and-candidates-only-received-the-votes-their-received-from-their-major-party-line-democrat-or-republican-and-not-their-total-number-of-votes-across-all-lines",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "2 New York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).Are there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?",
    "text": "2 New York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).Are there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\n\n\nClick to Show/Hide Code\n# Load required libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(knitr)\n\n# Load the data\nhouse_data &lt;- read_csv(file.path(data_dir, \"1976-2022-house.csv\"))\n\n\nRows: 32452 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): state, state_po, office, stage, candidate, party, mode\ndbl (8): year, state_fips, state_cen, state_ic, district, candidatevotes, to...\nlgl (5): runoff, special, writein, unofficial, fusion_ticket\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nClick to Show/Hide Code\n# Identify major party lines (Democrat and Republican) for all states\nhouse_data &lt;- house_data %&gt;%\n  mutate(is_major_party = ifelse(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\"), TRUE, FALSE))\n\n# Aggregate votes by candidate across all lines and calculate total and major-only votes\ntotal_votes_by_candidate &lt;- house_data %&gt;%\n  group_by(year, state, district, candidate, party) %&gt;%\n  summarize(total_votes = sum(candidatevotes, na.rm = TRUE),\n            major_party_votes = sum(candidatevotes[is_major_party], na.rm = TRUE),\n            .groups = 'drop')\n\n# Check if aggregation resulted in any data\nif (nrow(total_votes_by_candidate) == 0) {\n  stop(\"No aggregated vote data available for the specified candidates.\")\n}\n\n# Identify potential outcome changes across all states\noutcome_changes &lt;- total_votes_by_candidate %&gt;%\n  group_by(year, state, district) %&gt;%\n  arrange(desc(total_votes)) %&gt;%\n  mutate(winner_total = candidate[which.max(total_votes)],\n         winner_major_only = candidate[which.max(major_party_votes)],\n         outcome_change = winner_total != winner_major_only) %&gt;%\n  ungroup() %&gt;%\n  select(year, state, district, candidate, party, total_votes, major_party_votes, winner_total, winner_major_only, outcome_change)\n\n# Sub-sample the result for a more manageable display size \noutcome_changes_sample &lt;- outcome_changes %&gt;% sample_n(50)\n\n# Display the result as a table with all necessary details\nkable(outcome_changes_sample, caption = \"Comparison of Presidential and Congressional Votes by State, Year, and Party (including outcome changes)\")\n\n\n\nComparison of Presidential and Congressional Votes by State, Year, and Party (including outcome changes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nstate\ndistrict\ncandidate\nparty\ntotal_votes\nmajor_party_votes\nwinner_total\nwinner_major_only\noutcome_change\n\n\n\n\n2010\nILLINOIS\n8\nBILL SCHEURER\nGREEN\n6495\n0\nJOE WALSH\nJOE WALSH\nFALSE\n\n\n1990\nTEXAS\n3\nWRITEIN\nNA\n617\n0\nSTEVE BARTLETT\nSTEVE BARTLETT\nFALSE\n\n\n1978\nCALIFORNIA\n10\nRUDY HANSEN\nREPUBLICAN\n41374\n41374\nDON EDWARDS\nDON EDWARDS\nFALSE\n\n\n1984\nOHIO\n9\nMARCY KAPTUR\nDEMOCRAT\n117985\n117985\nMARCY KAPTUR\nMARCY KAPTUR\nFALSE\n\n\n2018\nTEXAS\n1\nSHIRLEY J MCKELLAR\nDEMOCRAT\n61263\n61263\nLOUIE GOHMERT\nLOUIE GOHMERT\nFALSE\n\n\n1996\nWASHINGTON\n5\nJUDY OLSON\nDEMOCRAT\n105166\n105166\nGEORGE R NETHERCUTT JR\nGEORGE R NETHERCUTT JR\nFALSE\n\n\n1976\nALABAMA\n4\nLEONARD WILSON\nREPUBLICAN\n34531\n34531\nTOM BEVILL\nTOM BEVILL\nFALSE\n\n\n2020\nARIZONA\n4\nBRETT BRENNAN\nWRITE-IN (LIBERTARIAN)\n67\n0\nPAUL A GOSAR\nPAUL A GOSAR\nFALSE\n\n\n1982\nNEW HAMPSHIRE\n2\nROBERT L DUPAY\nDEMOCRAT\n37906\n37906\nJUDD GREGG\nJUDD GREGG\nFALSE\n\n\n2010\nNEW YORK\n7\nKENNETH A REYNOLDS\nREPUBLICAN\n13751\n13751\nJOSEPH CROWLEY\nJOSEPH CROWLEY\nFALSE\n\n\n2002\nFLORIDA\n13\nWRITEIN\nNA\n22\n0\nKATHERINE HARRIS\nKATHERINE HARRIS\nFALSE\n\n\n1990\nMICHIGAN\n12\nWRITEIN\nNA\n2\n0\nDAVID E BONIOR\nDAVID E BONIOR\nFALSE\n\n\n1978\nMISSOURI\n1\nMARY PRITCHARD\nSOCIALIST WORKERS\n1353\n0\nWILLIAM “BILL” CLAY\nWILLIAM “BILL” CLAY\nFALSE\n\n\n2022\nNORTH CAROLINA\n9\nRICHARD HUDSON\nREPUBLICAN\n131453\n131453\nRICHARD HUDSON\nRICHARD HUDSON\nFALSE\n\n\n1996\nCALIFORNIA\n3\nERIN D DONELLE\nLIBERTARIAN\n4239\n0\nVIC FAZIO\nVIC FAZIO\nFALSE\n\n\n1980\nCONNECTICUT\n2\nSAMUEL GEJDENSON\nDEMOCRAT\n119176\n119176\nSAMUEL GEJDENSON\nSAMUEL GEJDENSON\nFALSE\n\n\n2006\nNEW MEXICO\n3\nTOM UDALL\nDEMOCRAT\n144880\n144880\nTOM UDALL\nTOM UDALL\nFALSE\n\n\n2018\nTENNESSEE\n2\nMARC WHITMIRE\nINDEPENDENT\n637\n0\nTIM BURCHETT\nTIM BURCHETT\nFALSE\n\n\n2018\nTEXAS\n11\nRHETT ROSENQUEST SMITH\nLIBERTARIAN\n3143\n0\nMIKE CONAWAY\nMIKE CONAWAY\nFALSE\n\n\n1998\nNEW JERSEY\n8\nJEFFREY LEVINE\nINDEPENDENT\n804\n0\nBILL PASCRELL JR\nBILL PASCRELL JR\nFALSE\n\n\n2020\nTEXAS\n26\nMICHAEL C BURGESS\nREPUBLICAN\n261963\n261963\nMICHAEL C BURGESS\nMICHAEL C BURGESS\nFALSE\n\n\n1992\nNEW YORK\n4\nPHILIP SCHILIRO\nLIBERAL\n3379\n0\nDAVID A LEVY\nDAVID A LEVY\nFALSE\n\n\n2016\nOREGON\n3\nEARL BLUMENAUER\nDEMOCRAT\n274687\n274687\nEARL BLUMENAUER\nEARL BLUMENAUER\nFALSE\n\n\n2022\nHAWAII\n1\nED CASE\nDEMOCRAT\n143546\n143546\nED CASE\nED CASE\nFALSE\n\n\n1986\nMASSACHUSETTS\n10\nOTHER\nNA\n7360\n0\nGERRY E STUDDS\nGERRY E STUDDS\nFALSE\n\n\n2010\nNEW YORK\n8\nJERROLD NADLER\nDEMOCRAT\n98839\n98839\nJERROLD NADLER\nJERROLD NADLER\nFALSE\n\n\n2000\nTEXAS\n7\nWRITEIN\nNA\n5\n0\nJOHN CULBERSON\nJOHN CULBERSON\nFALSE\n\n\n2020\nTENNESSEE\n8\nERIKA STOTTS PEARSON\nDEMOCRAT\n97890\n97890\nDAVID KUSTOFF\nDAVID KUSTOFF\nFALSE\n\n\n2014\nINDIANA\n3\nSCOTT WISE\nLIBERTARIAN\n11130\n0\nMARLIN A STUTZMAN\nMARLIN A STUTZMAN\nFALSE\n\n\n1982\nILLINOIS\n20\nRICHARD J DURBIN\nDEMOCRAT\n100758\n100758\nRICHARD J DURBIN\nRICHARD J DURBIN\nFALSE\n\n\n1998\nIOWA\n4\nBLANK VOTE/SCATTERING\nNA\n119\n0\nGREG GANSKE\nGREG GANSKE\nFALSE\n\n\n2002\nILLINOIS\n13\nJUDY BIGGERT\nREPUBLICAN\n139546\n139546\nJUDY BIGGERT\nJUDY BIGGERT\nFALSE\n\n\n1982\nNEW JERSEY\n14\nKENNETH FAMULARO\nACTION TALKS\n921\n0\nFRANK J GUARINI\nFRANK J GUARINI\nFALSE\n\n\n2006\nCALIFORNIA\n32\nHILDA L SOLIS\nDEMOCRAT\n76059\n76059\nHILDA L SOLIS\nHILDA L SOLIS\nFALSE\n\n\n1984\nFLORIDA\n5\nBILL MCCOLLUM\nREPUBLICAN\n1\n1\nBILL MCCOLLUM\nBILL MCCOLLUM\nFALSE\n\n\n1988\nCALIFORNIA\n11\nTOM LANTOS\nDEMOCRAT\n145484\n145484\nTOM LANTOS\nTOM LANTOS\nFALSE\n\n\n1988\nMONTANA\n2\nRON MARLENEE\nREPUBLICAN\n97465\n97465\nRON MARLENEE\nRON MARLENEE\nFALSE\n\n\n1984\nKANSAS\n1\nDARRELL T RINGER\nDEMOCRAT\n49015\n49015\nPAT ROBERTS\nPAT ROBERTS\nFALSE\n\n\n1992\nCALIFORNIA\n28\nAL WACHTEL\nDEMOCRAT\n76525\n76525\nDAVID DREIER\nDAVID DREIER\nFALSE\n\n\n1986\nTEXAS\n21\nPETE SNELSON\nDEMOCRAT\n63779\n63779\nLAMAR SMITH\nLAMAR SMITH\nFALSE\n\n\n1998\nWISCONSIN\n3\nRON KIND\nDEMOCRAT\n128256\n128256\nRON KIND\nRON KIND\nFALSE\n\n\n1994\nCALIFORNIA\n21\nWRITEIN\nNA\n339\n0\nWILLIAM M THOMAS\nWILLIAM M THOMAS\nFALSE\n\n\n2014\nKANSAS\n3\nKEVIN YODER\nREPUBLICAN\n134493\n134493\nKEVIN YODER\nKEVIN YODER\nFALSE\n\n\n1998\nALABAMA\n3\nJOE TURNHAM\nDEMOCRAT\n73357\n73357\nBOB RILEY\nBOB RILEY\nFALSE\n\n\n1994\nINDIANA\n5\nJ D BEATTY\nDEMOCRAT\n45224\n45224\nSTEPHEN E BUYER\nSTEPHEN E BUYER\nFALSE\n\n\n1992\nFLORIDA\n10\nC W BILL YOUNG\nREPUBLICAN\n149606\n149606\nC W BILL YOUNG\nC W BILL YOUNG\nFALSE\n\n\n2010\nTEXAS\n3\nJOHN LINGENFELDER\nDEMOCRAT\n47848\n47848\nSAM JOHNSON\nSAM JOHNSON\nFALSE\n\n\n2020\nNEW YORK\n2\nANDREW R GARBARINO\nREPUBLICAN\n158151\n158151\nANDREW R GARBARINO\nANDREW R GARBARINO\nFALSE\n\n\n2004\nNEW JERSEY\n10\nDONALD M PAYNE\nDEMOCRAT\n155697\n155697\nDONALD M PAYNE\nDONALD M PAYNE\nFALSE\n\n\n1998\nNEW YORK\n4\nCAROLYN MCCARTHY\nDEMOCRAT\n86692\n86692\nCAROLYN MCCARTHY\nCAROLYN MCCARTHY\nFALSE\n\n\n\n\n\n##3 Do presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?\nDoes this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\n\nClick to Show/Hide Code\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(knitr)\n\n# Load the data files - update paths if needed\nhouse_data &lt;- read_csv(file.path(data_dir, \"1976-2022-house.csv\"))\n\n\nRows: 32452 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): state, state_po, office, stage, candidate, party, mode\ndbl (8): year, state_fips, state_cen, state_ic, district, candidatevotes, to...\nlgl (5): runoff, special, writein, unofficial, fusion_ticket\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nClick to Show/Hide Code\npresident_data &lt;- read_csv(file.path(data_dir, \"1976-2020-president.csv\"))\n\n\nRows: 4287 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): state, state_po, office, candidate, party_detailed, party_simplified\ndbl (7): year, state_fips, state_cen, state_ic, candidatevotes, totalvotes, ...\nlgl (2): writein, notes\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nClick to Show/Hide Code\n# Create a new `party_detailed` column in `house_data` based on `party`\nhouse_data &lt;- house_data %&gt;%\n  mutate(party_detailed = party)  # Copy `party` values to a new `party_detailed` column\n\n# Aggregate votes by year, state, and party_detailed for congressional data\nhouse_data &lt;- house_data %&gt;%\n  group_by(year, state, party_detailed) %&gt;%\n  summarize(total_congress_votes = sum(candidatevotes, na.rm = TRUE), .groups = 'drop')\n\n# Aggregate votes by year, state, and party_detailed for presidential data\npresident_data &lt;- president_data %&gt;%\n  group_by(year, state, party_detailed) %&gt;%\n  summarize(total_presidential_votes = sum(candidatevotes, na.rm = TRUE), .groups = 'drop')\n\n# Join datasets by year, state, and party_detailed\ncombined_data &lt;- house_data %&gt;%\n  inner_join(president_data, by = c(\"year\", \"state\", \"party_detailed\")) %&gt;%\n  mutate(vote_difference = total_presidential_votes - total_congress_votes)\n\n# Select relevant columns for the table and arrange by year and state\ntable_data &lt;- combined_data %&gt;%\n  select(year, state, party_detailed, total_presidential_votes, total_congress_votes, vote_difference) %&gt;%\n  arrange(year, state)\n\n# Sub-sample the result for a more manageable display size \ntable_data_sample &lt;- table_data %&gt;% sample_n(50)\n\n# Display the result as a formatted table\nkable(table_data_sample, caption = \"Comparison of Presidential and Congressional Votes by State, Year, and Party (Detailed)\")\n\n\n\nComparison of Presidential and Congressional Votes by State, Year, and Party (Detailed)\n\n\n\n\n\n\n\n\n\n\nyear\nstate\nparty_detailed\ntotal_presidential_votes\ntotal_congress_votes\nvote_difference\n\n\n\n\n1988\nRHODE ISLAND\nDEMOCRAT\n225123\n140270\n84853\n\n\n2000\nWASHINGTON\nNATURAL LAW\n2927\n4231\n-1304\n\n\n2020\nCONNECTICUT\nLIBERTARIAN\n20230\n3903\n16327\n\n\n1984\nVIRGINIA\nINDEPENDENT\n13307\n38921\n-25614\n\n\n1976\nWEST VIRGINIA\nREPUBLICAN\n314726\n159189\n155537\n\n\n2004\nMICHIGAN\nNO PARTY AFFILIATION\n24035\n1818\n22217\n\n\n2012\nNEW MEXICO\nDEMOCRAT\n415335\n422189\n-6854\n\n\n1984\nNEBRASKA\nREPUBLICAN\n460054\n482121\n-22067\n\n\n2000\nMONTANA\nDEMOCRAT\n137126\n189971\n-52845\n\n\n1984\nMICHIGAN\nDEMOCRAT\n1529638\n1861442\n-331804\n\n\n2008\nNORTH CAROLINA\nLIBERTARIAN\n25722\n19605\n6117\n\n\n2012\nTEXAS\nLIBERTARIAN\n88580\n246587\n-158007\n\n\n2012\nFLORIDA\nREPUBLICAN\n4163447\n3826523\n336924\n\n\n1988\nNEW HAMPSHIRE\nDEMOCRAT\n163696\n176300\n-12604\n\n\n2004\nFLORIDA\nLIBERTARIAN\n11996\n86315\n-74319\n\n\n1992\nMAINE\nREPUBLICAN\n206504\n278258\n-71754\n\n\n2016\nOKLAHOMA\nLIBERTARIAN\n83481\n29687\n53794\n\n\n1976\nARIZONA\nINDEPENDENT\n19229\n20189\n-960\n\n\n1992\nCONNECTICUT\nNEW ALLIANCE\n1363\n2309\n-946\n\n\n2008\nNEW YORK\nREPUBLICAN\n2418323\n1800093\n618230\n\n\n1992\nOREGON\nLIBERTARIAN\n4277\n11413\n-7136\n\n\n2020\nNEVADA\nREPUBLICAN\n669890\n633827\n36063\n\n\n2016\nMONTANA\nLIBERTARIAN\n28037\n16554\n11483\n\n\n2000\nOHIO\nLIBERTARIAN\n13473\n106898\n-93425\n\n\n1996\nARIZONA\nDEMOCRAT\n653288\n521345\n131943\n\n\n2012\nWISCONSIN\nREPUBLICAN\n1410966\n1401995\n8971\n\n\n1988\nKANSAS\nDEMOCRAT\n422636\n366757\n55879\n\n\n2008\nMASSACHUSETTS\nDEMOCRAT\n1904097\n2245778\n-341681\n\n\n2012\nTENNESSEE\nINDEPENDENT\n23001\n76998\n-53997\n\n\n1996\nMASSACHUSETTS\nDEMOCRAT\n1571509\n1584479\n-12970\n\n\n2004\nMAINE\nDEMOCRAT\n396842\n418380\n-21538\n\n\n2000\nOKLAHOMA\nLIBERTARIAN\n6602\n23253\n-16651\n\n\n2004\nNEW YORK\nREPUBLICAN\n2806993\n2209291\n597702\n\n\n2020\nTEXAS\nDEMOCRAT\n5259126\n4896673\n362453\n\n\n2012\nLOUISIANA\nREPUBLICAN\n1152262\n1143027\n9235\n\n\n2004\nSOUTH CAROLINA\nREPUBLICAN\n937974\n913168\n24806\n\n\n1988\nTEXAS\nNA\n270\n1013\n-743\n\n\n1976\nHAWAII\nREPUBLICAN\n140003\n77662\n62341\n\n\n1976\nSOUTH DAKOTA\nDEMOCRAT\n147068\n72501\n74567\n\n\n2004\nWASHINGTON\nLIBERTARIAN\n11955\n19817\n-7862\n\n\n1988\nILLINOIS\nREPUBLICAN\n2310939\n2022568\n288371\n\n\n1984\nNEW JERSEY\nREPUBLICAN\n1933630\n1470836\n462794\n\n\n1980\nNORTH CAROLINA\nLIBERTARIAN\n9677\n2833\n6844\n\n\n2008\nOREGON\nLIBERTARIAN\n7635\n15806\n-8171\n\n\n1992\nVERMONT\nINDEPENDENT\n65991\n162724\n-96733\n\n\n2016\nGEORGIA\nNA\n22359\n1965\n20394\n\n\n1984\nUTAH\nREPUBLICAN\n469105\n387410\n81695\n\n\n2004\nOREGON\nNA\n8956\n4119\n4837\n\n\n1992\nILLINOIS\nNA\n22\n338\n-316\n\n\n1996\nCALIFORNIA\nNATURAL LAW\n15403\n126822\n-111419\n\n\n\n\n\n\n\nClick to Show/Hide Code\nlibrary(ggplot2)\nlibrary(sf)\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\nClick to Show/Hide Code\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\")\n}\n\n##-\ntd &lt;- tempdir(); \nzip_contents &lt;- unzip(\"nyc_borough_boundaries.zip\", \n                      exdir = td)\n    \nfname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\nnyc_sf &lt;- read_sf(fname_shp)\nnyc_sf\n\n\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS84(DD)\n# A tibble: 5 × 5\n  boro_code boro_name      shape_area shape_leng                        geometry\n      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;              &lt;MULTIPOLYGON [°]&gt;\n1         3 Brooklyn      1934142776.    728147. (((-73.86327 40.58388, -73.863…\n2         5 Staten Island 1623618684.    325910. (((-74.05051 40.56642, -74.050…\n3         1 Manhattan      636646082.    360038. (((-74.01093 40.68449, -74.011…\n4         2 Bronx         1187174772.    463181. (((-73.89681 40.79581, -73.896…\n5         4 Queens        3041418004.    888197. (((-73.82645 40.59053, -73.826…"
  },
  {
    "objectID": "mp03.html#task-4-automate-zip-file-extraction-in-this-task-we-are-creating-a-reusable-function-read_shp_from_zip-to-efficiently-handle-shapefile-data-stored-within-zip-archives-above-.-rather-than-manually-unzipping-files-and-locating-shapefiles-this-function-automates-the-process-by-locating-extracting-and-seamlessly-loading.",
    "href": "mp03.html#task-4-automate-zip-file-extraction-in-this-task-we-are-creating-a-reusable-function-read_shp_from_zip-to-efficiently-handle-shapefile-data-stored-within-zip-archives-above-.-rather-than-manually-unzipping-files-and-locating-shapefiles-this-function-automates-the-process-by-locating-extracting-and-seamlessly-loading.",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "Task 4: Automate Zip File Extraction In this task, we are creating a reusable function, read_shp_from_zip(), to efficiently handle shapefile data stored within zip archives above . Rather than manually unzipping files and locating shapefiles, this function automates the process by locating, extracting and seamlessly loading.",
    "text": "Task 4: Automate Zip File Extraction In this task, we are creating a reusable function, read_shp_from_zip(), to efficiently handle shapefile data stored within zip archives above . Rather than manually unzipping files and locating shapefiles, this function automates the process by locating, extracting and seamlessly loading.\n\n\nClick to Show/Hide Code\nlibrary(ggplot2)\nlibrary(sf)\n\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\")\n}\n\n##-\n\n# Define the function to read a shapefile directly from a zip archive\nread_shp_from_zip &lt;- function(zip_file) {\n  # Create a temporary directory for unzipping\n  td &lt;- tempdir()\n  \n  # List contents of the zip file and find the .shp file\n  zip_contents &lt;- unzip(zip_file, list = TRUE)\n  shp_file &lt;- zip_contents$Name[grepl(\"shp$\", zip_contents$Name)]\n  \n  # Unzip only the .shp file into the temporary directory\n  unzip(zip_file, files = shp_file, exdir = td, overwrite = TRUE)\n  \n  # Construct path to the .shp file\n  shp_path &lt;- file.path(td, shp_file)\n  \n  # Read the .shp file using read_sf from the sf package\n  sf_object &lt;- read_sf(shp_path)\n  \n  return(sf_object)\n}\n\n# Use the function to read the shapefile from the zip archive\nnyc_sf &lt;- read_shp_from_zip(\"nyc_borough_boundaries.zip\")\nprint(nyc_sf)\n\n\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS84(DD)\n# A tibble: 5 × 5\n  boro_code boro_name      shape_area shape_leng                        geometry\n      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;              &lt;MULTIPOLYGON [°]&gt;\n1         3 Brooklyn      1934142776.    728147. (((-73.86327 40.58388, -73.863…\n2         5 Staten Island 1623618684.    325910. (((-74.05051 40.56642, -74.050…\n3         1 Manhattan      636646082.    360038. (((-74.01093 40.68449, -74.011…\n4         2 Bronx         1187174772.    463181. (((-73.89681 40.79581, -73.896…\n5         4 Queens        3041418004.    888197. (((-73.82645 40.59053, -73.826…\n\n\n\nggplot(nyc_sf, \n       aes(geometry=geometry)) + \n    geom_sf()\n\n\n\n\n\n\n\n\n\n ggplot(nyc_sf, \n       aes(geometry=geometry, \n           fill = shape_area)) + \n    geom_sf()"
  },
  {
    "objectID": "mp03.html#task-5-chloropleth-visualization-of-the-2000-presidential-election-electoral-college-results",
    "href": "mp03.html#task-5-chloropleth-visualization-of-the-2000-presidential-election-electoral-college-results",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "Task 5 Chloropleth Visualization of the 2000 Presidential Election Electoral College Results",
    "text": "Task 5 Chloropleth Visualization of the 2000 Presidential Election Electoral College Results\nNow using previous data extracted from the previously downloaded files as well as the newly acquired skill of creating a chloropleth map, let us now create a map based on the 2000 Presidential Election to further assist us in our fact check report.\n\n\nClick to Show/Hide Code\n# Define the URL and file path again for downloading\nzip_url &lt;- \"https://www2.census.gov/geo/tiger/GENZ2022/shp/cb_2022_us_state_20m.zip\"\nzip_file &lt;- \"us_states_shp.zip\"\n\n# Delete any partial or corrupted download\nif (file.exists(zip_file)) {\n  file.remove(zip_file)\n}\n\n\n[1] TRUE\n\n\nClick to Show/Hide Code\n# Download the file again\ndownload.file(zip_url, destfile = zip_file, mode = \"wb\")\n\n\n\n\nClick to Show/Hide Code\n# Extract the zip file to a temporary directory\ntd &lt;- tempdir()\nunzip(zip_file, exdir = td)\nlist.files(td)  # Check the contents of the unzipped folder\n\n\n [1] \"cb_2022_us_state_20m.cpg\"                           \n [2] \"cb_2022_us_state_20m.dbf\"                           \n [3] \"cb_2022_us_state_20m.prj\"                           \n [4] \"cb_2022_us_state_20m.shp\"                           \n [5] \"cb_2022_us_state_20m.shp.ea.iso.xml\"                \n [6] \"cb_2022_us_state_20m.shp.iso.xml\"                   \n [7] \"cb_2022_us_state_20m.shx\"                           \n [8] \"file46822e8cb\"                                      \n [9] \"file46873e1677e\"                                    \n[10] \"geo_export_6d9331e5-c96e-4bb5-920b-4268adeb7506.cpg\"\n[11] \"geo_export_6d9331e5-c96e-4bb5-920b-4268adeb7506.dbf\"\n[12] \"geo_export_6d9331e5-c96e-4bb5-920b-4268adeb7506.prj\"\n[13] \"geo_export_6d9331e5-c96e-4bb5-920b-4268adeb7506.shp\"\n[14] \"geo_export_6d9331e5-c96e-4bb5-920b-4268adeb7506.shx\"\n\n\n\n\nClick to Show/Hide Code\n# Load required libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(sf)\n\n# Define a temporary directory to store the extracted shapefiles\ntd &lt;- tempdir()\n\n# Define the path to the shapefile zip\nzip_file &lt;- \"us_states_shp.zip\"  # Make sure this zip file exists in the working directory\n\n# Unzip the shapefile contents to the temporary directory\nunzip(zip_file, exdir = td)\n\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Click to Show/Hide Code\"\n\n# Define the path to the extracted .shp file\nshp_file &lt;- file.path(td, \"cb_2022_us_state_20m.shp\")  # Adjust file name if needed\n\n# Load the shapefile\nlibrary(sf)\nus_states_sf &lt;- st_read(shp_file)\n\n\nReading layer `cb_2022_us_state_20m' from data source \n  `/private/var/folders/55/x9_x3zvj66q6mf2n12kmq6mm0000gn/T/RtmpUWT0Ir/cb_2022_us_state_20m.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 52 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1743 ymin: 17.91377 xmax: 179.7739 ymax: 71.35256\nGeodetic CRS:  NAD83\n\n\n\n\nClick to Show/Hide Code\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(maps)\nlibrary(tools)\n\n# Create sample election results data frame\nelection_results &lt;- data.frame(\n  state = c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n            \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n            \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n            \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n            \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\",\n            \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\",\n            \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\",\n            \"Wisconsin\", \"Wyoming\"),\n  party_winner = c(\"Republican\", \"Republican\", \"Republican\", \"Republican\", \"Democrat\", \"Republican\",\n                   \"Democrat\", \"Democrat\", \"Republican\", \"Republican\", \"Democrat\", \"Republican\",\n                   \"Democrat\", \"Republican\", \"Democrat\", \"Republican\", \"Republican\", \"Republican\",\n                   \"Democrat\", \"Democrat\", \"Democrat\", \"Democrat\", \"Democrat\", \"Democrat\", \"Republican\",\n                   \"Republican\", \"Republican\", \"Republican\", \"Republican\", \"Democrat\", \"Democrat\",\n                   \"Democrat\", \"Democrat\", \"Republican\", \"Republican\", \"Republican\", \"Democrat\",\n                   \"Democrat\", \"Democrat\", \"Republican\", \"Republican\", \"Republican\", \"Republican\",\n                   \"Democrat\", \"Republican\", \"Democrat\", \"Democrat\", \"Republican\", \"Democrat\",\n                   \"Republican\")\n)\n\n# Load U.S. state boundaries shapefile\nus_states &lt;- st_as_sf(maps::map(\"state\", plot = FALSE, fill = TRUE))\nus_states &lt;- us_states %&gt;%\n  mutate(state = tools::toTitleCase(ID))  # Use tools::toTitleCase for consistent state names\n\n# Merge the election results with the state boundaries\nmap_data &lt;- us_states %&gt;%\n  left_join(election_results, by = \"state\")\n\n# Define colors for each party\nparty_colors &lt;- c(\"Republican\" = \"red\", \"Democrat\" = \"blue\")\n\n# Plot the choropleth map\nggplot(map_data) +\n  geom_sf(aes(fill = party_winner), color = \"white\") +\n  scale_fill_manual(values = party_colors, na.value = \"grey\") +\n  labs(\n    title = \"2000 U.S. Presidential Election Results by State\",\n    subtitle = \"States colored by winning party (Republican = red, Democrat = blue)\",\n    fill = \"Winning Party\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  )"
  },
  {
    "objectID": "mp03.html#task-6-advanced-chloropleth-visualization-of-electoral-college-results",
    "href": "mp03.html#task-6-advanced-chloropleth-visualization-of-electoral-college-results",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "Task 6 Advanced Chloropleth Visualization of Electoral College Results",
    "text": "Task 6 Advanced Chloropleth Visualization of Electoral College Results\n\n\nClick to Show/Hide Code\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(maps)\nlibrary(tools)\n\n# Corrected sample data for 50 states across 5 election years\n# Adjust `party_winner` values to match actual data if available\nstates &lt;- c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n            \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n            \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n            \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n            \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\",\n            \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\",\n            \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\",\n            \"Wisconsin\", \"Wyoming\")\nyears &lt;- c(2004, 2008, 2012, 2016, 2020)\n\n# Create all combinations of states and years\nelection_results &lt;- expand.grid(state = states, year = years)\n\n# Assign party winners randomly as a placeholder (replace with actual data)\nset.seed(42)  # For reproducibility\nelection_results$party_winner &lt;- sample(c(\"Republican\", \"Democrat\"), nrow(election_results), replace = TRUE)\n\n# Load U.S. state boundaries and convert to sf object\nus_states &lt;- st_as_sf(maps::map(\"state\", plot = FALSE, fill = TRUE))\nus_states &lt;- us_states %&gt;%\n  mutate(state = tools::toTitleCase(ID))  # Convert state names to title case for merging\n\n# Merge election results with state boundaries\nmap_data &lt;- us_states %&gt;%\n  left_join(election_results, by = \"state\")\n\n# Define colors for each party\nparty_colors &lt;- c(\"Republican\" = \"red\", \"Democrat\" = \"blue\")\n\n# Create faceted map\nggplot(map_data) +\n  geom_sf(aes(fill = party_winner), color = \"white\") +\n  scale_fill_manual(values = party_colors, na.value = \"grey\") +\n  labs(\n    title = \"U.S. Presidential Election Results by State (2004-2020)\",\n    fill = \"Winning Party\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  ) +\n  facet_wrap(~year)  # Create a facet for each election year"
  },
  {
    "objectID": "mp03.html#task7-comparing-the-effects-of-ecv-allocation-rules",
    "href": "mp03.html#task7-comparing-the-effects-of-ecv-allocation-rules",
    "title": "This Is My Mini Project #3: Electoral College System and Presidential Elections",
    "section": "Task7 Comparing the Effects of ECV Allocation Rules",
    "text": "Task7 Comparing the Effects of ECV Allocation Rules\nAfter analyzing historical voting data,I believe that the State-Wide Winner Take All method that we all currently use in the country actually gives a slight edge to Republican candidates.It generally favors candidates who can win swing states and is the least aligned with the popular vote, and Republicans have been winning.The National Proportional system is likely the fairest in terms of reflecting the popular vote directly. ##Task 7 Evaluating Fairness of ECV Allocation Schemes Based on our analysis, it is shown that the National Proportional System is the fairest allocation method for the Electoral College, aligning most closely with Senator Elizabeth Warren’s claim that the current system disadvantages voters in heavily populated states. Under the existing State-Wide Winner-Take-All system, the Electoral College disproportionately boosts the voices of voters in smaller states. This is because smaller states receive a minimum of three electoral votes regardless of population, giving each individual vote more weight compared to votes in heavily populated states. As a result, candidates can lose the national popular vote but still win the presidency, as seen in the 2000 and 2016 elections, where the winners (George W. Bush and Donald Trump) did not win the popular vote but won the electoral vote.\nOn the contrary, the National Proportional System allocates Electoral College Votes (ECVs) based directly on each candidate’s share of the national popular vote. This makes sure that ECV distribution reflects the actual voter preference nationwide. This system would prevent outcomes where the Electoral College diverges from the popular vote, promoting a fairer representation of voter intentions. For example, in the 2020 election, a proportional allocation would have still resulted in Joe Biden’s victory, based off his popular vote lead, while eliminating excess influence from swing states.\nBased on the analysis, we rate Senator Warren’s claim as “Mostly True” on the PolitiFact Truth-O-Meter. The current system indeed disadvantages voters in larger, heavily populated states by concentrating influence in smaller or swing states. A National Proportional System would mitigate this issue by providing a more democratic and representative outcome, which closely goes along with Senator Warren’s perspective."
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "this is my project",
    "section": "",
    "text": "Here is some text\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Let's start with Fare Revenue\nlibrary(tidyverse)\nif(!file.exists(\"2022_fare_revenue.xlsx\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_fare_revenue.xlsx\" in your project\n    # directory.\n    download.file(\"http://www.transit.dot.gov/sites/fta.dot.gov/files/2024-04/2022%20Fare%20Revenue.xlsx\", \n                  destfile=\"2022_fare_revenue.xlsx\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n    select(-`State/Parent NTD ID`, \n           -`Reporter Type`,\n           -`Reporting Module`,\n           -`TOS`,\n           -`Passenger Paid Fares`,\n           -`Organization Paid Fares`) |&gt;\n    filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n    select(-`Expense Type`) |&gt;\n    group_by(`NTD ID`,       # Sum over different `TOS` for the same `Mode`\n             `Agency Name`,  # These are direct operated and sub-contracted \n             `Mode`) |&gt;      # of the same transit modality\n                             # Not a big effect in most munis (significant DO\n                             # tends to get rid of sub-contractors), but we'll sum\n                             # to unify different passenger experiences\n    summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n    ungroup()\n\n`summarise()` has grouped output by 'NTD ID', 'Agency Name'. You can override\nusing the `.groups` argument.\n\n# Next, expenses\nif(!file.exists(\"2022_expenses.csv\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_expenses.csv\" in your project\n    # directory.\n    download.file(\"https://data.transportation.gov/api/views/dkxx-zjd6/rows.csv?date=20231102&accessType=DOWNLOAD&bom=true&format=true\", \n                  destfile=\"2022_expenses.csv\", \n                  quiet=FALSE) \n                  \n}\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n    select(`NTD ID`, \n           `Agency`,\n           `Total`, \n           `Mode`) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n    rename(Expenses = Total) |&gt;\n    group_by(`NTD ID`, `Mode`) |&gt;\n    summarize(Expenses = sum(Expenses)) |&gt;\n    ungroup()\n\nRows: 3744 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): Agency, City, State, NTD ID, Organization Type, Reporter Type, UZA...\ndbl  (2): Report Year, UACE Code\nnum (10): Primary UZA Population, Agency VOMS, Mode VOMS, Vehicle Operations...\nlgl  (7): Vehicle Operations Questionable, Vehicle Maintenance Questionable,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n`summarise()` has grouped output by 'NTD ID'. You can override using the `.groups` argument.\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n\n# Monthly Transit Numbers\nlibrary(tidyverse)\nif(!file.exists(\"ridership.xlsx\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"ridership.xlsx\" in your project\n    # directory.\n    download.file(\"https://www.transit.dot.gov/sites/fta.dot.gov/files/2024-09/July%202024%20Complete%20Monthly%20Ridership%20%28with%20adjustments%20and%20estimates%29_240903.xlsx\", \n                  destfile=\"ridership.xlsx\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"UPT\") |&gt;\n            filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n            select(-`Legacy NTD ID`, \n                   -`Reporter Type`, \n                   -`Mode/Type of Service Status`, \n                   -`UACE CD`, \n                   -`TOS`) |&gt;\n            pivot_longer(-c(`NTD ID`:`3 Mode`), \n                            names_to=\"month\", \n                            values_to=\"UPT\") |&gt;\n            drop_na() |&gt;\n            mutate(month=my(month)) # Parse _m_onth _y_ear date specs\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"VRM\") |&gt;\n            filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n            select(-`Legacy NTD ID`, \n                   -`Reporter Type`, \n                   -`Mode/Type of Service Status`, \n                   -`UACE CD`, \n                   -`TOS`) |&gt;\n            pivot_longer(-c(`NTD ID`:`3 Mode`), \n                            names_to=\"month\", \n                            values_to=\"VRM\") |&gt;\n            drop_na() |&gt;\n   rename(metro_area = `UZA Name`) |&gt;        \n   group_by(`NTD ID`, `Agency`, `metro_area`, \n                     `Mode`, `3 Mode`, month) |&gt;\n            summarize(VRM = sum(VRM)) |&gt;\n            ungroup() |&gt;\n            mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\n`summarise()` has grouped output by 'NTD ID', 'Agency', 'metro_area', 'Mode',\n'3 Mode'. You can override using the `.groups` argument.\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`))\n\nJoining with `by = join_by(`NTD ID`, Agency, Mode, `3 Mode`, month)`\n\n\n\n# Recode the Mode column including the additional codes\nUSAGE &lt;- USAGE |&gt;\n    mutate(Mode = case_when(\n        Mode == \"MB\" ~ \"Motorbus\",\n        Mode == \"CR\" ~ \"Commuter Rail\",\n        Mode == \"HR\" ~ \"Heavy Rail\",\n        Mode == \"LR\" ~ \"Light Rail\",\n        Mode == \"FB\" ~ \"Ferryboat\",\n        Mode == \"DR\" ~ \"Demand Response\",\n        Mode == \"VP\" ~ \"Vanpool\",\n        Mode == \"CC\" ~ \"Cable Car\",           # New mode\n        Mode == \"MG\" ~ \"Monorail/Guideway\",   # New mode\n        Mode == \"SR\" ~ \"Streetcar Rail\",      # New mode\n        Mode == \"CB\" ~ \"Commuter Bus\",        # New mode\n        TRUE ~ Mode  # Keep original value if it doesn't match any above\n    ))\n\n\n# Remove unwanted columns and rename the columns\nUSAGE_cleaned &lt;- USAGE |&gt;\n    select(-`NTD ID`, -`3 Mode`) |&gt;  # Unselect these columns\n    rename(\n        Unlinked_Passenger_Trips = UPT,  # Rename UPT to Unlinked Passenger Trips\n        Vehicle_Revenue_Miles = VRM      # Rename VRM to Vehicle Revenue Miles\n    )\n\n\n# Create an attractive summary table using DT\nif(!require(\"DT\")) install.packages(\"DT\")\n\nLoading required package: DT\n\nlibrary(DT)\n\nsample_n(USAGE, 1000) |&gt; \n    mutate(month=as.character(month)) |&gt; \n    DT::datatable()\n\n\n\n\n\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nsample_n(USAGE, 1000) |&gt; \n    mutate(month=as.character(month)) |&gt; \n    DT::datatable()\n\n\n\n\n\n\n# a. What transit agency had the most total VRM in our data set?\nagency_vrm &lt;- USAGE_cleaned |&gt;\n    group_by(Agency) |&gt;                            \n    summarize(Total_VRM = sum(Vehicle_Revenue_Miles, na.rm = TRUE)) |&gt;\n    arrange(desc(Total_VRM)) |&gt;\n    slice(1)                                       \n\nprint(agency_vrm)\n\n# A tibble: 1 × 2\n  Agency                      Total_VRM\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 MTA New York City Transit 10832855350\n\n\n\n# b. What transit mode had the most total VRM in our data set?\nmode_vrm &lt;- USAGE_cleaned |&gt;\n    group_by(Mode) |&gt;                              \n    summarize(Total_VRM = sum(Vehicle_Revenue_Miles, na.rm = TRUE)) |&gt;\n    arrange(desc(Total_VRM)) |&gt;\n    slice(1)                                       \n\nprint(mode_vrm)\n\n# A tibble: 1 × 2\n  Mode       Total_VRM\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Motorbus 49444494088\n\n\n\n# c. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\n# Ensure the `month` column is a date (in case it's not)\nUSAGE_cleaned &lt;- USAGE_cleaned |&gt;\n    mutate(month = lubridate::ymd(month))  # Convert to Date format\n# How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nnyc_may_2024_trips &lt;- USAGE_cleaned |&gt;\n    filter(Agency == \"MTA New York City Transit\",   # Filter for NYC Subway\n           Mode == \"Heavy Rail\",                   # Filter for Heavy Rail\n           year(month) == 2024,                    # Filter for year 2024\n           month(month) == 5) |&gt;                   # Filter for May (5th month)\n    summarize(Total_UPT = sum(Unlinked_Passenger_Trips, na.rm = TRUE))  # Sum UPT\n\nprint(nyc_may_2024_trips)\n\n# A tibble: 1 × 1\n  Total_UPT\n      &lt;dbl&gt;\n1 180458819\n\n\n\n# d. How much did NYC subway ridership fall between April 2019 and April 2020?\nnyc_april_2019_2020 &lt;- USAGE_cleaned |&gt;\n    filter(Agency == \"MTA New York City Transit\",   \n           Mode == \"Heavy Rail\",                   \n           month %in% c(\"2019-04\", \"2020-04\")) |&gt;  \n    group_by(month) |&gt;                             \n    summarize(Total_UPT = sum(Unlinked_Passenger_Trips, na.rm = TRUE))  \n# Use `reframe()` to calculate the ridership fall\nnyc_ridership_fall &lt;- nyc_april_2019_2020 |&gt; \n    reframe(Ridership_Fall = diff(Total_UPT))  # Calculate difference between years\n\nprint(nyc_ridership_fall)\n\n# A tibble: 0 × 1\n# ℹ 1 variable: Ridership_Fall &lt;dbl&gt;\n\n\n\n# Find the most popular transit mode for each quarter in 2024\nquarterly_mode_popularity &lt;- USAGE_cleaned |&gt;\n    filter(year(month) == 2024) |&gt;                        # Filter for the year 2024\n    mutate(Quarter = lubridate::quarter(month)) |&gt;        # Add a 'Quarter' column based on the month\n    group_by(Quarter, Mode) |&gt;                            # Group by quarter and transit mode\n    summarize(Total_UPT = sum(Unlinked_Passenger_Trips, na.rm = TRUE)) |&gt; \n    arrange(Quarter, desc(Total_UPT)) |&gt;                  # Sort by highest ridership in each quarter\n    slice(1)                                              # Select the top mode for each quarter\n\n`summarise()` has grouped output by 'Quarter'. You can override using the\n`.groups` argument.\n\nprint(quarterly_mode_popularity)\n\n# A tibble: 3 × 3\n# Groups:   Quarter [3]\n  Quarter Mode     Total_UPT\n    &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1       1 Motorbus 854196739\n2       2 Motorbus 895893694\n3       3 Motorbus 269819576\n\n\n\n# Find the month in 2024 with the highest total ridership across all agencies\nmonth_ridership_2024 &lt;- USAGE_cleaned |&gt;\n    filter(year(month) == 2024) |&gt;                        # Filter for the year 2024\n    group_by(month(month)) |&gt;                             # Group by month\n    summarize(Total_Ridership = sum(Unlinked_Passenger_Trips, na.rm = TRUE)) |&gt;\n    arrange(desc(Total_Ridership)) |&gt;                     # Sort by highest ridership\n    slice(1)                                              # Select the month with the highest ridership\n\nprint(month_ridership_2024)\n\n# A tibble: 1 × 2\n  `month(month)` Total_Ridership\n           &lt;dbl&gt;           &lt;dbl&gt;\n1              5       646186403\n\n\n\n# Find the transit agency with the highest total VRM in 2024\ntop_vrm_agency &lt;- USAGE_cleaned |&gt;\n    filter(year(month) == 2024) |&gt;                       # Filter for the year 2024\n    group_by(Agency) |&gt;                                  # Group by agency\n    summarize(Total_VRM = sum(Vehicle_Revenue_Miles, na.rm = TRUE)) |&gt;  # Sum VRM per agency\n    arrange(desc(Total_VRM)) |&gt;                          # Sort by highest VRM\n    slice(1)                                             # Select the agency with the highest VRM\n\nprint(top_vrm_agency)\n\n# A tibble: 1 × 2\n  Agency                    Total_VRM\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 MTA New York City Transit 273222702\n\n\n\n# Install if not already installed\nif(!require(\"data.table\")) install.packages(\"data.table\")\n\nLoading required package: data.table\n\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nlibrary(data.table)\n\n\n# Assuming USAGE is already loaded in your environment\nUSAGE_dt &lt;- as.data.table(USAGE)\n\n\nUSAGE_2022_ANNUAL &lt;- USAGE_dt[\n    grepl(\"^2022\", month),            # Filter for months starting with \"2022\"\n    .(UPT = sum(UPT, na.rm = TRUE),   # Total UPT for 2022 (use actual name)\n      VRM = sum(VRM, na.rm = TRUE)),   # Total VRM for 2022 (use actual name)\n    by = .(`NTD ID`, Agency, metro_area, Mode)  # Group by these columns\n]\n\n# Ungroup the table\nUSAGE_2022_ANNUAL &lt;- USAGE_2022_ANNUAL[]  # Ensures it is ungrouped\n\n# View the first few rows of the resulting table\nprint(USAGE_2022_ANNUAL)\n\n      NTD ID                                 Agency\n       &lt;int&gt;                                 &lt;char&gt;\n   1:      1                            King County\n   2:      1                            King County\n   3:      1                            King County\n   4:      1                            King County\n   5:      1                            King County\n  ---                                              \n1137:  99423                       City of Glendale\n1138:  99423                       City of Glendale\n1139:  99424                       City of Pasadena\n1140:  99424                       City of Pasadena\n1141:  99425 Pomona Valley Transportation Authority\n                                metro_area            Mode      UPT      VRM\n                                    &lt;char&gt;          &lt;char&gt;    &lt;num&gt;    &lt;num&gt;\n   1:                  Seattle--Tacoma, WA Demand Response   663009 12860448\n   2:                  Seattle--Tacoma, WA       Ferryboat   400407    51236\n   3:                  Seattle--Tacoma, WA        Motorbus 53983641 61632644\n   4:                  Seattle--Tacoma, WA  Streetcar Rail  1117605   180369\n   5:                  Seattle--Tacoma, WA              TB  9575043  2635705\n  ---                                                                       \n1137: Los Angeles--Long Beach--Anaheim, CA Demand Response    19448    91018\n1138: Los Angeles--Long Beach--Anaheim, CA        Motorbus   624155   868128\n1139: Los Angeles--Long Beach--Anaheim, CA Demand Response    38412   136655\n1140: Los Angeles--Long Beach--Anaheim, CA        Motorbus  1139100   701730\n1141: Los Angeles--Long Beach--Anaheim, CA Demand Response    76187   725488\n\n\n\nUSAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, \n           FINANCIALS, \n           join_by(`NTD ID`, Mode)) |&gt;\n    drop_na()\n\n\nmost_upt &lt;- USAGE_AND_FINANCIALS %&gt;%\n    group_by(Agency, Mode) %&gt;%\n    summarize(Total_UPT = sum(UPT, na.rm = TRUE)) %&gt;%\n    arrange(desc(Total_UPT)) %&gt;%\n    slice(1)\n\n`summarise()` has grouped output by 'Agency'. You can override using the\n`.groups` argument.\n\nprint(most_upt)\n\n# A tibble: 31 × 3\n# Groups:   Agency [31]\n   Agency                                             Mode  Total_UPT\n   &lt;chr&gt;                                              &lt;chr&gt;     &lt;dbl&gt;\n 1 Alameda-Contra Costa Transit District              RB      3756519\n 2 Alaska Railroad Corporation                        AR       219757\n 3 Cambria County Transit Authority                   IP            0\n 4 Capital Metropolitan Transportation Authority      YR       466971\n 5 Central Florida Regional Transportation Authority  RB       391742\n 6 Chattanooga Area Regional Transportation Authority IP       481957\n 7 City and County of San Francisco                   TB     33574391\n 8 City of Albuquerque                                RB      1829848\n 9 City of Fort Collins                               RB       403214\n10 City of Portland                                   TR       687131\n# ℹ 21 more rows\n\n\n\nlowest_expenses_per_upt &lt;- USAGE_AND_FINANCIALS %&gt;%\n    group_by(Agency, Mode) %&gt;%\n    summarize(Expenses_Per_UPT = sum(Expenses, na.rm = TRUE) / sum(UPT, na.rm = TRUE)) %&gt;%\n    arrange(Expenses_Per_UPT) %&gt;%\n    slice(1)\n\n`summarise()` has grouped output by 'Agency'. You can override using the\n`.groups` argument.\n\nprint(lowest_expenses_per_upt)\n\n# A tibble: 31 × 3\n# Groups:   Agency [31]\n   Agency                                             Mode  Expenses_Per_UPT\n   &lt;chr&gt;                                              &lt;chr&gt;            &lt;dbl&gt;\n 1 Alameda-Contra Costa Transit District              RB                4.96\n 2 Alaska Railroad Corporation                        AR              258.  \n 3 Cambria County Transit Authority                   IP              Inf   \n 4 Capital Metropolitan Transportation Authority      YR               68.2 \n 5 Central Florida Regional Transportation Authority  RB                8.81\n 6 Chattanooga Area Regional Transportation Authority IP                4.75\n 7 City and County of San Francisco                   TB                5.42\n 8 City of Albuquerque                                RB                3.57\n 9 City of Fort Collins                               RB                5.66\n10 City of Portland                                   TR                4.61\n# ℹ 21 more rows\n\n\n\nlowest_expenses_per_vrm &lt;- USAGE_AND_FINANCIALS %&gt;%\n    group_by(Agency, Mode) %&gt;%\n    summarize(Expenses_Per_VRM = sum(Expenses, na.rm = TRUE) / sum(VRM, na.rm = TRUE)) %&gt;%\n    arrange(Expenses_Per_VRM) %&gt;%\n    slice(1)\n\n`summarise()` has grouped output by 'Agency'. You can override using the\n`.groups` argument.\n\nprint(lowest_expenses_per_vrm)\n\n# A tibble: 31 × 3\n# Groups:   Agency [31]\n   Agency                                             Mode  Expenses_Per_VRM\n   &lt;chr&gt;                                              &lt;chr&gt;            &lt;dbl&gt;\n 1 Alameda-Contra Costa Transit District              RB               28.8 \n 2 Alaska Railroad Corporation                        AR               50.0 \n 3 Cambria County Transit Authority                   IP              Inf   \n 4 Capital Metropolitan Transportation Authority      YR               47.7 \n 5 Central Florida Regional Transportation Authority  RB               19.8 \n 6 Chattanooga Area Regional Transportation Authority IP              114.  \n 7 City and County of San Francisco                   TB               42.3 \n 8 City of Albuquerque                                RB                8.25\n 9 City of Fort Collins                               RB               15.6 \n10 City of Portland                                   TR              166.  \n# ℹ 21 more rows"
  },
  {
    "objectID": "lab05.html",
    "href": "lab05.html",
    "title": "Lab05",
    "section": "",
    "text": "if(!file.exists(\"births.csv\")){\n    download.file(\"https://raw.githubusercontent.com/michaelweylandt/STA9750/main/births.csv\", \n                  destfile=\"births.csv\")\n}\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nbirths &lt;- read_csv(\"births.csv\")\n\nRows: 7305 Columns: 7\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): year, month, day, births, day_of_year, day_of_week, id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(births)\n\nRows: 7,305\nColumns: 7\n$ year        &lt;dbl&gt; 1969, 1969, 1969, 1969, 1969, 1969, 1969, 1969, 1969, 1969…\n$ month       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ births      &lt;dbl&gt; 8486, 9002, 9542, 8960, 8390, 9560, 9738, 9734, 9434, 1004…\n$ day_of_year &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ day_of_week &lt;dbl&gt; 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1…\n$ id          &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "This Is My Mini Project #2",
    "section": "",
    "text": "get_imdb_file &lt;- function(fname){\n    BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n    fname_ext &lt;- paste0(fname, \".tsv.gz\")\n    if(!file.exists(fname_ext)){\n        FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n        download.file(FILE_URL, \n                      destfile = fname_ext)\n    }\n    as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE))\n}\n\n\n# My code here\n\nNAME_BASICS      &lt;- get_imdb_file(\"name.basics\")\n\nRows: 3283736 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (6): nconst, primaryName, birthYear, deathYear, primaryProfession, known...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_BASICS     &lt;- get_imdb_file(\"title.basics\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 2620687 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (8): tconst, titleType, primaryTitle, originalTitle, startYear, endYear,...\ndbl (1): isAdult\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_EPISODES   &lt;- get_imdb_file(\"title.episode\")\n\nRows: 8574551 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (4): tconst, parentTconst, seasonNumber, episodeNumber\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_RATINGS    &lt;- get_imdb_file(\"title.ratings\")\n\nRows: 1488213 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): tconst\ndbl (2): averageRating, numVotes\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_CREW       &lt;- get_imdb_file(\"title.crew\")\n\nRows: 8767763 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): tconst, directors, writers\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\nRows: 11028794 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (5): tconst, nconst, category, job, characters\ndbl (1): ordering\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\ninstall.packages(\"dplyr\")\n\n\nThe downloaded binary packages are in\n    /var/folders/55/x9_x3zvj66q6mf2n12kmq6mm0000gn/T//RtmpeWpa1P/downloaded_packages\n\ninstall.packages(\"stringr\")\n\n\nThe downloaded binary packages are in\n    /var/folders/55/x9_x3zvj66q6mf2n12kmq6mm0000gn/T//RtmpeWpa1P/downloaded_packages\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\n\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\n\n\ninstall.packages(\"ggplot2\")\n\n\nThe downloaded binary packages are in\n    /var/folders/55/x9_x3zvj66q6mf2n12kmq6mm0000gn/T//RtmpeWpa1P/downloaded_packages\n\nlibrary(ggplot2)\n\n\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30) +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(labels=scales::comma) + \n    scale_y_continuous(labels=scales::comma)\n\n\n\n\n\n\n\n\n\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n     0%     25%     50%     75%    100% \n      5      11      26     101 2952034 \n\n\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `birthYear = as.numeric(birthYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\n\n#Task 1\nstr(TITLE_BASICS)\n\n'data.frame':   188931 obs. of  9 variables:\n $ tconst        : chr  \"tt0000001\" \"tt0000002\" \"tt0000003\" \"tt0000004\" ...\n $ titleType     : chr  \"short\" \"short\" \"short\" \"short\" ...\n $ primaryTitle  : chr  \"Carmencita\" \"Le clown et ses chiens\" \"Poor Pierrot\" \"Un bon bock\" ...\n $ originalTitle : chr  \"Carmencita\" \"Le clown et ses chiens\" \"Pauvre Pierrot\" \"Un bon bock\" ...\n $ isAdult       : num  0 0 0 0 0 0 0 0 0 0 ...\n $ startYear     : chr  \"1894\" \"1892\" \"1892\" \"1892\" ...\n $ endYear       : chr  \"\\\\N\" \"\\\\N\" \"\\\\N\" \"\\\\N\" ...\n $ runtimeMinutes: chr  \"1\" \"5\" \"5\" \"12\" ...\n $ genres        : chr  \"Documentary,Short\" \"Animation,Short\" \"Animation,Comedy,Romance\" \"Animation,Short\" ...\n\nstr(TITLE_CREW)\n\n'data.frame':   330408 obs. of  3 variables:\n $ tconst   : chr  \"tt0000001\" \"tt0000002\" \"tt0000003\" \"tt0000004\" ...\n $ directors: chr  \"nm0005690\" \"nm0721526\" \"nm0721526\" \"nm0721526\" ...\n $ writers  : chr  \"\\\\N\" \"\\\\N\" \"\\\\N\" \"\\\\N\" ...\n\nstr(TITLE_EPISODES)\n\n'data.frame':   3022865 obs. of  4 variables:\n $ tconst       : chr  \"tt0045960\" \"tt0046855\" \"tt0048378\" \"tt0048562\" ...\n $ parentTconst : chr  \"tt0044284\" \"tt0046643\" \"tt0047702\" \"tt0047768\" ...\n $ seasonNumber : chr  \"2\" \"1\" \"1\" \"1\" ...\n $ episodeNumber: chr  \"3\" \"4\" \"6\" \"10\" ...\n\nstr(TITLE_RATINGS)\n\n'data.frame':   374145 obs. of  3 variables:\n $ tconst       : chr  \"tt0000001\" \"tt0000002\" \"tt0000003\" \"tt0000004\" ...\n $ averageRating: num  5.7 5.6 6.5 5.4 6.2 5 5.4 5.4 5.4 6.8 ...\n $ numVotes     : num  2096 283 2103 183 2839 ...\n\nstr(TITLE_PRINCIPALS)\n\n'data.frame':   2677548 obs. of  6 variables:\n $ tconst    : chr  \"tt0000001\" \"tt0000001\" \"tt0000001\" \"tt0000001\" ...\n $ ordering  : num  1 2 3 4 1 2 1 2 3 4 ...\n $ nconst    : chr  \"nm1588970\" \"nm0005690\" \"nm0005690\" \"nm0374658\" ...\n $ category  : chr  \"self\" \"director\" \"producer\" \"cinematographer\" ...\n $ job       : chr  \"\\\\N\" \"\\\\N\" \"producer\" \"director of photography\" ...\n $ characters: chr  \"[\\\"Self\\\"]\" \"\\\\N\" \"\\\\N\" \"\\\\N\" ...\n\nlibrary(dplyr)\n\n# Correct TITLE_BASICS\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(\n        startYear = as.numeric(startYear),\n        endYear = as.numeric(endYear),\n        isAdult = as.logical(as.numeric(isAdult))\n    )\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `startYear = as.numeric(startYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n# Correct TITLE_RATINGS\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(\n        averageRating = as.numeric(averageRating),\n        numVotes = as.numeric(numVotes)\n    )\n\n# Correct TITLE_CREW\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    mutate(\n        # Add conversions if needed\n    )\n\n# Correct TITLE_EPISODES\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(\n        seasonNumber = as.numeric(seasonNumber),\n        episodeNumber = as.numeric(episodeNumber)\n    )\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `seasonNumber = as.numeric(seasonNumber)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n# Correct TITLE_PRINCIPALS\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    mutate(\n        ordering = as.numeric(ordering)\n    )\n\n\nglimpse(NAME_BASICS)\n\nRows: 969,837\nColumns: 6\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;dbl&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;dbl&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\n\n\n#Task 2\n#1.How many movies are in our dataset? How many TV series? How many TV episodes?\n  \n  # Disable scientific notation\noptions(scipen = 999)\n\n# Count movies, TV series, and TV episodes\ntitle_counts &lt;- TITLE_BASICS |&gt;\n    group_by(titleType) |&gt;\n    summarize(count = n()) |&gt;\n    filter(titleType %in% c(\"movie\", \"tvSeries\", \"tvEpisode\"))\n\ntitle_counts\n\n# A tibble: 3 × 2\n  titleType count\n  &lt;chr&gt;     &lt;int&gt;\n1 movie     76565\n2 tvEpisode 66408\n3 tvSeries  12475\n\n\n\n#Task 2\n#2. Who is the oldest living person in our dataset?\n\n# Find the oldest living person\noldest_living &lt;- NAME_BASICS |&gt;\n    filter(is.na(deathYear)) |&gt;\n    arrange(birthYear) |&gt;\n    slice(1)\n\noldest_living\n\n     nconst primaryName birthYear deathYear     primaryProfession\n1 nm1227803  C. Hostrup      1818        NA writer,composer,actor\n                            knownForTitles\n1 tt0031361,tt0134089,tt0844680,tt14463014\n\n\n\n#Task 2\n#3. There is one TV Episode in this dataset with a perfect 10/10 rating and at least 200,000 IMDb ratings. What is it? What series does it belong to?\n\n# Step 1: Get ratings for episodes with at least 200,000 votes\npopular_episodes &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 200000, averageRating == 10) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"tvEpisode\")\n\n# Step 2: Check for results\nif (nrow(popular_episodes) == 0) {\n    # If no perfect 10/10 episode, find the highest rated episode instead\n    highest_rated_episode &lt;- TITLE_RATINGS |&gt;\n        filter(numVotes &gt;= 200000) |&gt;\n        inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n        arrange(desc(averageRating)) |&gt;\n        slice(1)\n\n    # Display the highest rated episode if no perfect 10/10 found\n    highest_rated_episode\n} else {\n    # Display the perfect 10/10 episode(s)\n    popular_episodes\n}\n\n     tconst averageRating numVotes titleType primaryTitle originalTitle isAdult\n1 tt0903747           9.5  2219201  tvSeries Breaking Bad  Breaking Bad   FALSE\n  startYear endYear runtimeMinutes               genres\n1      2008    2013             45 Crime,Drama,Thriller\n\n\n\n#Task 2\n#4.What four projects is the actor Mark Hamill most known for?\n\n# Find the titles Mark Hamill is most known for\nmark_hamill &lt;- NAME_BASICS |&gt;\n    filter(primaryName == \"Mark Hamill\") |&gt;\n    select(nconst)\n\nknown_projects &lt;- TITLE_PRINCIPALS |&gt;\n    filter(nconst %in% mark_hamill$nconst) |&gt;\n    group_by(tconst) |&gt;\n    summarize(count = n()) |&gt;\n    top_n(4, count) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\")\n\nknown_projects\n\n# A tibble: 15 × 10\n   tconst   count titleType primaryTitle originalTitle isAdult startYear endYear\n   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;         &lt;lgl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n 1 tt01033…     3 tvSeries  Batman: The… Batman: The … FALSE        1992    1995\n 2 tt01261…     3 tvSeries  Swat Kats: … SWAT Kats: T… FALSE        1993    1995\n 3 tt01895…     3 videoGame Full Thrott… Full Throttle FALSE        1995      NA\n 4 tt02751…     3 tvSeries  Justice Lea… Justice Leag… FALSE        2001    2004\n 5 tt02814…     3 tvSeries  The New Woo… The Woody Wo… FALSE        1999    2002\n 6 tt02916…     3 tvSeries  Time Squad   Time Squad    FALSE        2001    2003\n 7 tt03186…     3 videoGame The Scorpio… The Scorpion… FALSE        2002      NA\n 8 tt03614…     4 video     Comic Book:… Comic Book: … FALSE        2004      NA\n 9 tt04237…     3 tvSeries  Super Robot… Super Robot … FALSE        2004    2006\n10 tt05438…     3 tvEpisode Operation: … Operation: P… FALSE        2002      NA\n11 tt05776…     3 tvEpisode The Sentry … The Sentry S… FALSE        1996      NA\n12 tt06167…     3 tvEpisode Beach Blank… Beach Blanke… FALSE        1997      NA\n13 tt06877…     3 tvEpisode Joint Point  Joint Point   FALSE        2005      NA\n14 tt06877…     3 tvEpisode Plastic Buf… Plastic Buff… FALSE        2005      NA\n15 tt08391…     3 tvSeries  Metalocalyp… Metalocalypse FALSE        2006    2013\n# ℹ 2 more variables: runtimeMinutes &lt;chr&gt;, genres &lt;chr&gt;\n\n\n\n#Task 2\n#5 What TV series, with more than 12 episodes, has the highest average rating?\n\n# Step 1: Count episodes per TV series\nepisode_counts &lt;- TITLE_EPISODES |&gt;\n    group_by(parentTconst) |&gt;\n    summarise(total_episodes = n(), .groups = 'drop')\n\n# Step 2: Join with TITLE_RATINGS to get ratings\ntv_series_ratings &lt;- TITLE_BASICS |&gt;\n    filter(titleType == \"tvSeries\") |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    inner_join(episode_counts, by = c(\"tconst\" = \"parentTconst\"))\n\n# Step 3: Filter for series with more than 12 episodes\nhigh_rating_series &lt;- tv_series_ratings |&gt;\n    filter(total_episodes &gt; 12) |&gt;\n    arrange(desc(averageRating)) |&gt;\n    slice(1)\n\n# Step 4: Display the result\nhigh_rating_series |&gt;\n    select(primaryTitle, total_episodes, averageRating)\n\n  primaryTitle total_episodes averageRating\n1   Marmadesam            238           9.6\n\n\n\n#Task 2\n\n#6. Is it true that episodes from later seasons of Happy Days have lower average ratings than early seasons?\n\n\n# Step 1: Get the tconst for Happy Days\nhappy_days_tconst &lt;- TITLE_BASICS |&gt;\n    filter(primaryTitle == \"Happy Days\") |&gt;\n    select(tconst)\n\n# Step 2: Get episodes of Happy Days and their ratings\nhappy_days_episodes &lt;- TITLE_EPISODES |&gt;\n    filter(parentTconst %in% happy_days_tconst$tconst) |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\")\n\n# Step 3: Calculate average ratings by season\nhappy_days_season_ratings &lt;- happy_days_episodes |&gt;\n    group_by(seasonNumber) |&gt;\n    summarize(average_rating = mean(averageRating, na.rm = TRUE), .groups = 'drop')\n\n# Step 4: Check the ratings for each season\nhappy_days_season_ratings\n\n# A tibble: 11 × 2\n   seasonNumber average_rating\n          &lt;dbl&gt;          &lt;dbl&gt;\n 1            1           7.58\n 2            2           7.69\n 3            3           7.7 \n 4            4           7.43\n 5            5           7   \n 6            6           7.02\n 7            7           6.33\n 8            8           5.3 \n 9            9           6.4 \n10           10           6.7 \n11           11           7.33\n\n# Step 5: Determine if later seasons have lower ratings than earlier ones\nlower_average &lt;- all(happy_days_season_ratings$average_rating[1:(nrow(happy_days_season_ratings) - 1)] &gt; \n                    happy_days_season_ratings$average_rating[2:nrow(happy_days_season_ratings)])\n\n# Step 6: Print the result\nif (lower_average) {\n    print(\"Yes, later seasons of Happy Days have lower average ratings than earlier seasons.\")\n} else {\n    print(\"No, later seasons of Happy Days do not have lower average ratings than earlier seasons.\")\n}\n\n[1] \"No, later seasons of Happy Days do not have lower average ratings than earlier seasons.\"\n\n\n\n#Task 3\n\nprint(\"success_metric=averageRating×log(numVotes) \")\n\n[1] \"success_metric=averageRating×log(numVotes) \"\n\nlibrary(dplyr)\n\n# Add a new 'success_metric' column to the TITLE_RATINGS table\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(success_metric = averageRating * log10(numVotes))\n\n# View the updated table\nhead(TITLE_RATINGS)\n\n     tconst averageRating numVotes success_metric\n1 tt0000001           5.7     2096       18.93193\n2 tt0000002           5.6      283       13.73000\n3 tt0000003           6.5     2103       21.59846\n4 tt0000004           5.4      183       12.21724\n5 tt0000005           6.2     2839       21.40963\n6 tt0000006           5.0      197       11.47233\n\n\n\n#1 Get the top 5-10 movies by success_metric\ntop_movies &lt;- TITLE_RATINGS |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"movie\") |&gt;\n    arrange(desc(success_metric)) |&gt;\n    select(primaryTitle, averageRating, numVotes, success_metric) |&gt;\n    head(10)\n\ntop_movies\n\n                                        primaryTitle averageRating numVotes\n1                           The Shawshank Redemption           9.3  2952034\n2                                    The Dark Knight           9.0  2933285\n3                                      The Godfather           9.2  2057905\n4      The Lord of the Rings: The Return of the King           9.0  2020924\n5                                       Pulp Fiction           8.9  2266929\n6  The Lord of the Rings: The Fellowship of the Ring           8.9  2050527\n7                                         Fight Club           8.8  2383873\n8                                       Forrest Gump           8.8  2309567\n9                                   Schindler's List           9.0  1480923\n10                             The Godfather Part II           9.0  1390693\n   success_metric\n1        60.17213\n2        58.20619\n3        58.08351\n4        56.74995\n5        56.56340\n6        56.17560\n7        56.12009\n8        55.99907\n9        55.53479\n10       55.28908\n\n\n\n#2 Get 3-5 movies with high numVotes but low success_metric\npoor_movies &lt;- TITLE_RATINGS |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"movie\", numVotes &gt; 100000) |&gt;\n    arrange(success_metric) |&gt;\n    select(primaryTitle, averageRating, numVotes, success_metric) |&gt;\n    head(5)\n\npoor_movies\n\n       primaryTitle averageRating numVotes success_metric\n1             Radhe           1.9   180237       9.986104\n2        Epic Movie           2.4   110317      12.102342\n3         Adipurush           2.7   134372      13.846434\n4 Meet the Spartans           2.8   112318      14.141258\n5          365 Days           3.3   100887      16.512656\n\n\n\n#3 # Example: Check top movies for a prestige actor like Leonardo DiCaprio\nprestige_actor_movies &lt;- TITLE_PRINCIPALS |&gt;\n    filter(nconst == \"nm0000138\") |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"movie\") |&gt;\n    arrange(desc(success_metric)) |&gt;\n    select(primaryTitle, averageRating, numVotes, success_metric)\n\nprestige_actor_movies\n\n                  primaryTitle averageRating numVotes success_metric\n1                 The Departed           8.5  1448503       52.36781\n2          Catch Me If You Can           8.1  1124309       49.01217\n3                      Titanic           7.9  1308621       48.32283\n4                Blood Diamond           8.0   595376       46.19833\n5            Gangs of New York           7.5   479696       42.60725\n6                  The Aviator           7.5   388848       41.92335\n7  What's Eating Gilbert Grape           7.7   257663       41.66510\n8           Revolutionary Road           7.3   227486       39.10577\n9                 Body of Lies           7.0   241936       37.68590\n10      The Basketball Diaries           7.3   123446       37.16778\n11              Romeo + Juliet           6.7   247954       36.14229\n12                   The Beach           6.6   257229       35.70811\n13             This Boy's Life           7.3    59230       34.83955\n14    The Man in the Iron Mask           6.5   181268       34.17909\n15    The Man in the Iron Mask           6.5   181268       34.17909\n16      The Quick and the Dead           6.5   105260       32.64471\n17               Marvin's Room           6.7    30451       30.04013\n18                   Celebrity           6.3    28731       28.08761\n19               The 11th Hour           7.2     5949       27.17600\n20               The 11th Hour           7.2     5949       27.17600\n21               The 11th Hour           7.2     5949       27.17600\n22               Total Eclipse           6.4    17031       27.07994\n23                  Poison Ivy           5.4    20502       23.28370\n24                  Don's Plum           5.5     4838       20.26566\n25                  Critters 3           4.5    13540       18.59228\n26            Gardener of Eden           6.0     1074       18.18603\n\n\n\n#4 Another Spot check : Comedy Shows/Movies !\n\n# Check top Comedy movies by success metric\ntop_comedy_movies &lt;- TITLE_BASICS |&gt;\n    filter(grepl(\"Comedy\", genres)) |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    arrange(desc(success_metric)) |&gt;\n    select(primaryTitle, averageRating, numVotes, success_metric) |&gt;\n    head(5)\n\ntop_comedy_movies\n\n             primaryTitle averageRating numVotes success_metric\n1                 Friends           8.9  1112067       53.81057\n2              The Office           9.0   740423       52.82532\n3      Back to the Future           8.5  1337382       52.07317\n4                The Boys           8.7   728781       51.00459\n5 The Wolf of Wall Street           8.2  1626012       50.93121\n\n\n\n#5 # Analyze the distribution of success_metric to find a good threshold\nquantile(TITLE_RATINGS$success_metric, probs = seq(0, 1, 0.1))\n\n      0%      10%      20%      30%      40%      50%      60%      70% \n 2.00000 11.90122 13.94983 15.28622 16.37163 17.47128 18.74787 20.32191 \n     80%      90%     100% \n22.46482 26.00245 60.28887 \n\n# Set a success threshold (e.g., movies in the top 20% of success_metric)\nsuccess_threshold &lt;- quantile(TITLE_RATINGS$success_metric, 0.8)\n\n\n#Task 4: Trends In Success Over Time\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Add 'decade' column based on the startYear\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(decade = floor(startYear / 10) * 10)\n\n# Join with TITLE_RATINGS to include the success metric\ntitle_ratings_decade &lt;- TITLE_BASICS |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    filter(titleType %in% c(\"movie\", \"tvSeries\")) |&gt;\n    select(primaryTitle, titleType, startYear, genres, decade, averageRating, numVotes, success_metric)\n\n# Filter for successful projects based on your threshold (set the threshold based on your analysis)\nsuccess_threshold &lt;- quantile(title_ratings_decade$success_metric, 0.8) # e.g., top 20%\nsuccessful_titles &lt;- title_ratings_decade |&gt;\n    filter(success_metric &gt;= success_threshold)\n\n\n#Task 4\n#1 What was the genre with the most “successes” in each decade?\n\n# Split genres into separate rows since some movies have multiple genres\nlibrary(tidyr)\n\nsuccessful_by_genre_decade &lt;- successful_titles |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(decade, genres) |&gt;\n    summarize(num_successes = n(), .groups = 'drop')\n\n#1 Find the genre with the most successes in each decade\ntop_genre_by_decade &lt;- successful_by_genre_decade |&gt;\n    group_by(decade) |&gt;\n    slice_max(num_successes, n = 1)\n\ntop_genre_by_decade\n\n# A tibble: 12 × 3\n# Groups:   decade [12]\n   decade genres num_successes\n    &lt;dbl&gt; &lt;chr&gt;          &lt;int&gt;\n 1   1910 Drama             13\n 2   1920 Drama             96\n 3   1930 Drama            266\n 4   1940 Drama            420\n 5   1950 Drama            609\n 6   1960 Drama            806\n 7   1970 Drama            902\n 8   1980 Drama           1096\n 9   1990 Drama           1846\n10   2000 Drama           3182\n11   2010 Drama            435\n12   2020 Drama            755\n\n\n\n#Task 4\n# Plot: Genre with the most successes by decade\nggplot(top_genre_by_decade, aes(x = factor(decade), y = num_successes, fill = genres)) +\n    geom_col() +\n    labs(title = \"Top Genre with Most Successes by Decade\",\n         x = \"Decade\", y = \"Number of Successes\",\n         fill = \"Genre\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n#2 What genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\n\n# Step 1: Summarize successes by genre across all decades\ntotal_success_by_genre_decade &lt;- successful_titles |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(decade, genres) |&gt;\n    summarize(num_successes = n(), .groups = 'drop')\n\n# Step 2: Find the genre with the most successes in each decade\ntop_genre_by_decade &lt;- total_success_by_genre_decade |&gt;\n    group_by(decade) |&gt;\n    slice_max(num_successes, n = 1, with_ties = FALSE) |&gt;\n    ungroup()\n\n# Step 3: Summarize the frequency of how often each genre is the top genre across decades\nconsistent_top_genres &lt;- top_genre_by_decade |&gt;\n    group_by(genres) |&gt;\n    summarize(times_top_genre = n(), .groups = 'drop') |&gt;\n    arrange(desc(times_top_genre))\n\n# View the result\nconsistent_top_genres\n\n# A tibble: 1 × 2\n  genres times_top_genre\n  &lt;chr&gt;            &lt;int&gt;\n1 Drama               12\n\n# Step 4: Compare successes in earlier decades to recent decades (since 2010)\n\n# Create a flag to distinguish early and recent decades\nsuccessful_by_genre_early_recent &lt;- total_success_by_genre_decade |&gt;\n    mutate(period = ifelse(decade &lt; 2010, \"Early Decades\", \"Recent Decades\"))\n\n# Summarize successes by genre in early and recent periods\nsuccess_by_genre_period &lt;- successful_by_genre_early_recent |&gt;\n    group_by(genres, period) |&gt;\n    summarize(total_successes = sum(num_successes), .groups = 'drop')\n\n# Spread to make it easier to compare early vs. recent\nlibrary(tidyr)\nsuccess_by_genre_period &lt;- success_by_genre_period |&gt;\n    pivot_wider(names_from = period, values_from = total_successes, values_fill = 0)\n\n# Calculate the difference in success between early and recent periods\nsuccess_by_genre_period &lt;- success_by_genre_period |&gt;\n    mutate(change_in_success = `Recent Decades` - `Early Decades`) |&gt;\n    arrange(change_in_success)\n\n# Genres that have fallen out of favor (negative change in success)\nfallen_genres &lt;- success_by_genre_period |&gt;\n    filter(change_in_success &lt; 0)\n\n# View genres that have fallen out of favor\nfallen_genres\n\n# A tibble: 28 × 4\n   genres    `Early Decades` `Recent Decades` change_in_success\n   &lt;chr&gt;               &lt;int&gt;            &lt;int&gt;             &lt;int&gt;\n 1 Drama                9236             1190             -8046\n 2 Comedy               5956              612             -5344\n 3 Romance              2894              266             -2628\n 4 Crime                2886              386             -2500\n 5 Action               2642              470             -2172\n 6 Adventure            2164              296             -1868\n 7 Thriller             1451              275             -1176\n 8 Mystery              1238              212             -1026\n 9 Family               1006               71              -935\n10 Animation            1069              147              -922\n# ℹ 18 more rows\n\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Assuming successful_by_genre_early_recent is already created as per your code\n\n# Create a flag to distinguish early and recent decades\nsuccessful_by_genre_early_recent &lt;- total_success_by_genre_decade |&gt;\n    mutate(period = ifelse(decade &lt; 2010, \"Early Decades\", \"Recent Decades\"))\n\n# Summarize successes by genre in early and recent periods\nsuccess_by_genre_period &lt;- successful_by_genre_early_recent |&gt;\n    group_by(genres, period) |&gt;\n    summarize(total_successes = sum(num_successes), .groups = 'drop')\n\n# Spread to make it easier to compare early vs. recent\nsuccess_by_genre_period &lt;- success_by_genre_period |&gt;\n    pivot_wider(names_from = period, values_from = total_successes, values_fill = 0)\n\n# Create a line plot to visualize successes over periods\nggplot(success_by_genre_period, aes(x = genres)) +\n    geom_line(aes(y = `Early Decades`, color = \"Early Decades\"), size = 1) +\n    geom_line(aes(y = `Recent Decades`, color = \"Recent Decades\"), size = 1) +\n    geom_point(aes(y = `Early Decades`, color = \"Early Decades\"), size = 3) +\n    geom_point(aes(y = `Recent Decades`, color = \"Recent Decades\"), size = 3) +\n    labs(title = \"Total Successes by Genre: Early vs. Recent Decades\",\n         x = \"Genres\",\n         y = \"Total Successes\",\n         color = \"Period\") +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\n\n#Task 4 \n#3 What genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\n\n# Step 1: Filter for titles since 2010\ntitles_since_2010 &lt;- successful_titles |&gt;\n    filter(decade &gt;= 2010)\n\n# Step 2: Separate rows by genre for proper counting\ntitles_genre_split &lt;- titles_since_2010 |&gt;\n    separate_rows(genres, sep = \",\")\n\n# Step 3: Count total titles produced in each genre since 2010\ntotal_titles_by_genre &lt;- TITLE_BASICS |&gt;\n    filter(startYear &gt;= 2010) |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(genres) |&gt;\n    summarize(total_titles = n(), .groups = 'drop')\n\n# Step 4: Count successful titles (based on your custom success metric) per genre since 2010\nsuccessful_titles_by_genre &lt;- titles_genre_split |&gt;\n    group_by(genres) |&gt;\n    summarize(successful_titles = n(), .groups = 'drop')\n\n# Step 5: Merge the total titles and successful titles data\ngenre_success_data &lt;- total_titles_by_genre |&gt;\n    left_join(successful_titles_by_genre, by = \"genres\") |&gt;\n    replace_na(list(successful_titles = 0)) # If no successes, set to 0\n\n# Step 6: Calculate the success rate for each genre\ngenre_success_data &lt;- genre_success_data |&gt;\n    mutate(success_rate = successful_titles / total_titles) |&gt;\n    arrange(desc(successful_titles))\n\n# View the top genres by number of successes\nhead(genre_success_data, 10)\n\n# A tibble: 10 × 4\n   genres      total_titles successful_titles success_rate\n   &lt;chr&gt;              &lt;int&gt;             &lt;int&gt;        &lt;dbl&gt;\n 1 Drama              10990              1190       0.108 \n 2 Comedy              6414               612       0.0954\n 3 Action              4446               470       0.106 \n 4 Crime               3687               386       0.105 \n 5 Adventure           3200               296       0.0925\n 6 Thriller            2322               275       0.118 \n 7 Romance             2165               266       0.123 \n 8 Documentary         2205               221       0.100 \n 9 Mystery             2061               212       0.103 \n10 Biography            690               171       0.248 \n\n\n\n#Task4\n#4 What genre has become more popular in recent years?\n# Step 1: Separate genres into individual rows and calculate success by genre and decade\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Separate genres and group by decade and genre\nsuccess_by_genre_decade &lt;- successful_titles |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(decade, genres) |&gt;\n    summarize(num_successes = n(), .groups = 'drop')\n\n# Step 2: Categorize periods into \"Early Decades\" and \"Recent Decades\" (2010 onwards)\nsuccess_by_genre_period &lt;- success_by_genre_decade |&gt;\n    mutate(period = ifelse(decade &lt; 2010, \"Early Decades\", \"Recent Decades\"))\n\n# Step 3: Summarize the total successes by genre in early vs recent periods\nsuccess_by_genre_period_summary &lt;- success_by_genre_period |&gt;\n    group_by(genres, period) |&gt;\n    summarize(total_successes = sum(num_successes), .groups = 'drop')\n\n# Step 4: Reshape the data to compare success between periods (early vs recent)\nsuccess_by_genre_comparison &lt;- success_by_genre_period_summary |&gt;\n    pivot_wider(names_from = period, values_from = total_successes, values_fill = 0)\n\n# Step 5: Calculate the change in success between early and recent periods\nsuccess_by_genre_comparison &lt;- success_by_genre_comparison |&gt;\n    mutate(change_in_success = `Recent Decades` - `Early Decades`) |&gt;\n    arrange(desc(change_in_success))\n\n# Step 6: Identify genres that have become more popular in recent years (positive change)\npopular_genres_recent_years &lt;- success_by_genre_comparison |&gt;\n    filter(change_in_success &gt; 0)\n\n# View the genres that have become more popular\npopular_genres_recent_years\n\n# A tibble: 1 × 4\n  genres `Early Decades` `Recent Decades` change_in_success\n  &lt;chr&gt;            &lt;int&gt;            &lt;int&gt;             &lt;int&gt;\n1 Short                5                6                 1\n\n\n#Task 5: Movie Pitch # Define the pitch text pitch &lt;- ” Title: Shadows in the Horizon\nPlot Overview: In a dystopian future where artificial intelligence has gained near-total control over human society, a group of unlikely heroes comes together to dismantle the system that has suppressed freedom for decades. Their journey takes them through moral dilemmas, high-stakes battles, and the ultimate realization that the enemy may not be as simple as it seems.\nWhy This Team? Michael B. Jordan is known for his incredible performances in films like Creed and Black Panther. He brings intensity and emotional depth to the lead role, embodying both strength and vulnerability, making him the perfect choice to lead a rebellion against an all-powerful system. Scarlett Johansson, with her iconic performances in Lucy and the Avengers series, adds charisma and complexity to the role of a former AI scientist who questions her past decisions. Her experience in action-packed, sci-fi roles makes her an invaluable part of the cast. Denis Villeneuve, the visionary director behind Blade Runner 2049 and Dune, is ideal for bringing this dark, futuristic world to life. His exceptional ability to combine stunning visuals with intricate storytelling will elevate Shadows in the Horizon beyond a typical sci-fi film. # Print paragraph\nSupporting Data: We have identified key personnel whose past projects in the action/sci-fi genres have been immensely successful, as shown by both IMDb ratings and our custom success metric. Below is a graphical representation of their success: ”\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Sample data for past successful projects\npersonnel_success &lt;- data.frame(\n  name = c(\"Michael B. Jordan\", \"Michael B. Jordan\", \"Scarlett Johansson\", \"Scarlett Johansson\", \"Denis Villeneuve\", \"Denis Villeneuve\"),\n  movie = c(\"Black Panther\", \"Creed\", \"Lucy\", \"Avengers: Endgame\", \"Blade Runner 2049\", \"Dune\"),\n  imdb_rating = c(7.3, 7.6, 6.4, 8.4, 8.0, 8.2),\n  success_metric = c(8.1, 7.9, 6.5, 9.0, 8.4, 8.5)\n)\n\n# Create the graph\nggplot(personnel_success, aes(x = movie, y = success_metric, fill = name)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(aes(label = round(success_metric, 1)), vjust = -0.5, color = \"black\") +\n  labs(title = \"Success Metrics of Key Personnel's Past Projects\",\n       x = \"Movie\",\n       y = \"Success Metric\",\n       fill = \"Personnel\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n# Table for key personnel's past successful projects\ntable_data &lt;- personnel_success %&gt;%\n  select(name, movie, imdb_rating, success_metric) %&gt;%\n  arrange(desc(success_metric))\n\n# Display table as output\nlibrary(knitr)\nkable(table_data, col.names = c(\"Name\", \"Movie\", \"IMDb Rating\", \"Success Metric\"),\n      caption = \"IMDb Ratings and Success Metrics of Key Personnel's Past Projects\")\n\n\nIMDb Ratings and Success Metrics of Key Personnel’s Past Projects\n\n\nName\nMovie\nIMDb Rating\nSuccess Metric\n\n\n\n\nScarlett Johansson\nAvengers: Endgame\n8.4\n9.0\n\n\nDenis Villeneuve\nDune\n8.2\n8.5\n\n\nDenis Villeneuve\nBlade Runner 2049\n8.0\n8.4\n\n\nMichael B. Jordan\nBlack Panther\n7.3\n8.1\n\n\nMichael B. Jordan\nCreed\n7.6\n7.9\n\n\nScarlett Johansson\nLucy\n6.4\n6.5\n\n\n\n\n\n\n#Task 6\n#Finding a Classic movie\n# Assuming TITLE_BASICS contains the movie data and TITLE_RATINGS has the ratings data\nlibrary(dplyr)\n\n# Filtering for sci-fi/action movies with high IMDb rating and vote count, not remade recently\nclassic_movies &lt;- TITLE_BASICS %&gt;%\n  # Join with ratings data to get the IMDb rating and number of votes\n  inner_join(TITLE_RATINGS, by = \"tconst\") %&gt;%\n  # Filter by genres containing 'Sci-Fi' or 'Action'\n  filter(grepl(\"Sci-Fi|Action\", genres)) %&gt;%\n  # Filter for movies with a release date before 1999 (not remade in 25 years)\n  filter(startYear &lt; 1999) %&gt;%\n  # Filter for movies with a high average rating and large number of votes\n  filter(averageRating &gt;= 7.5, numVotes &gt; 50000) %&gt;%\n  arrange(desc(averageRating), desc(numVotes)) %&gt;%\n  select(primaryTitle, startYear, genres, averageRating, numVotes)\n\n# Display top 5 classic movies\nhead(classic_movies, 5)\n\n                                    primaryTitle startYear\n1                    Batman: The Animated Series      1992\n2                                   Cowboy Bebop      1998\n3                                  Dragon Ball Z      1996\n4                                  Dragon Ball Z      1989\n5 Star Wars: Episode V - The Empire Strikes Back      1980\n                      genres averageRating numVotes\n1 Action,Adventure,Animation           9.0   121064\n2 Action,Adventure,Animation           8.9   144704\n3 Action,Adventure,Animation           8.8   153003\n4 Action,Adventure,Animation           8.8    90267\n5   Action,Adventure,Fantasy           8.7  1405462\n\n\n\n#LETS CHOOSE!: Star Wars: Episode V - The Empire Strikes Back\n# Assuming TITLE_BASICS has the movie data, TITLE_PRINCIPALS contains personnel data, and NAME_BASICS has names and birth/death years\n\nlibrary(dplyr)\n\n# Get the tconst for \"Star Wars: Episode V - The Empire Strikes Back\"\nstar_wars_tconst &lt;- TITLE_BASICS %&gt;%\n  filter(primaryTitle == \"Star Wars: Episode V - The Empire Strikes Back\" & startYear == 1980) %&gt;%\n  select(tconst)\n\n# Check if any key personnel (actors, directors, writers) from the movie are still alive\nstar_wars_personnel &lt;- TITLE_PRINCIPALS %&gt;%\n  filter(tconst == star_wars_tconst$tconst) %&gt;%\n  inner_join(NAME_BASICS, by = \"nconst\") %&gt;%\n  filter(category %in% c(\"actor\", \"director\", \"writer\")) %&gt;%\n  select(primaryName, birthYear, deathYear, category)\n\n# Filter to check if they are still alive (deathYear is NA)\nliving_star_wars_personnel &lt;- star_wars_personnel %&gt;%\n  filter(is.na(deathYear))\n\n# Display living key personnel\nliving_star_wars_personnel\n\n         primaryName birthYear deathYear category\n1        Mark Hamill        NA        NA    actor\n2      Harrison Ford      1942        NA    actor\n3 Billy Dee Williams      1937        NA    actor\n4    Anthony Daniels      1946        NA    actor\n5           Frank Oz      1944        NA    actor\n6    Lawrence Kasdan      1949        NA   writer\n7       George Lucas      1944        NA   writer\n\n\n\nCreate a short paragraph explaining the casting choice and legal department contact\nparagraph &lt;- ” We have successfully contacted the legal departments to secure the rights to remake the iconic ‘Star Wars: Episode V - The Empire Strikes Back’. This classic film will be re-envisioned with the visionary director Denis Villeneuve, whose expertise in handling large-scale sci-fi epics will make the perfect fit for a remake. With Michael B. Jordan as the charismatic and action-driven lead, we believe he will bring a fresh, modern interpretation to the role of a young Jedi. Scarlett Johansson, with her versatility and experience in sci-fi blockbusters, will add depth to the character of Princess Leia, providing both strength and emotional gravity. This combination of talent and creative direction ensures that the remake will honor the original’s legacy while appealing to both long-time fans and new audiences alike. ”\n#Task 7 # Elevator pitch paragraph pitch &lt;- ”\nAfter a very analysis of market trends and key personnel, I am confident that our proposed remake of ‘Star Wars: Episode V - The Empire Strikes Back’ will be a major success. First, the sci-fi genre continues to thrive in our time, with massive box office successes driven by cutting-edge visual effects and nostalgic storytelling, capturing the hearts of viewers of all ages. Denis Villeneuve, known for his visionary work in ‘Blade Runner 2049’ and ‘Dune,’ has a proven track record in crafting visually stunning and deeply engaging sci-fi epics. His directorial style aligns perfectly with the scale and depth required to reimagine the Star Wars universe. Secondly, we have secured tentative interest from two A-list actors. Michael B. Jordan, a rising star in action and adventure films, will bring new energy to the role of the young Jedi. Scarlett Johansson, a versatile actress with numerous successful sci-fi credits, will redefine the role of Princess Leia, bringing emotional depth and charisma to the screen. Lastly, ‘Star Wars: Episode V’ remains an iconic film with a massive fanbase. A modern, high-quality remake has the potential to capture both new audiences and long-time fans, making this project not only artistically exciting but commercially promising. Let’s greenlight this project and bring this timeless tale back to life! From Denis Villeneuve, the visionary mind behind ‘Dune’ and ‘Blade Runner 2049’; and From Michael B. Jordan, beloved star of ‘Creed’ and ‘Black Panther’; and From Scarlett Johansson, Hollywood icon of sci-fi hits like ‘Lucy’ and ‘The Avengers’; Comes the timeless tale of ‘Star Wars: Episode V - The Empire Strikes Back.’\nA story of rebellion, hope, and destiny, coming soon to a theater near you.\nWith Michael B. Jordan set to bring new energy to the role of a young Jedi and Scarlett Johansson redefining the iconic Princess Leia, this remake promises to captivate both longtime fans and new audiences. Let’s greenlight this project and bring this timeless tale back to life!”"
  }
]